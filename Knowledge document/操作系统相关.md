# 进程与线程的区别和联系
    区别：
        a：进程是资源分配的基本单位，线程是cpu调度，或者说是程序执行的最小单位；
        b：进程有独立的地址空间，启动一个新的进程，系统必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段。而运行一个进程中的线程，它们之间共享大部分数据，使用相同的地址空间，当然，线程是拥有自己的栈空间；
        c：线程之间的通信比较方便。同一进程下的线程共享数据（比如全局变量，静态变量），通过这些数据来通信不仅快捷而且方便，当然如何处理好这些访问的同步与互斥正是编写多线程程序的难点。而进程之间的通信只能通过进程通信的方式进行；
        d：多进程比多线程程序要健壮。一个线程死掉整个进程就死掉了，但是在保护模式下，一个进程死掉对另一个进程没有直接影响；
        e：线程的执行与进程是有区别的。每个独立的线程有自己的一个程序入口，顺序执行序列和程序的出口，但是线程不能独立执行，必须依附与程序之中由应用程序提供多个线程的并发控制；
    联系：
        创建进程和创建线程在内核中都是使用的clone函数，只是传入的参数不同而已，创建进程时，clone函数使用的cow机制，当新进程没有写数据操作时，共享父进程的地址空间，当有写操作时，将父进程地址空间拷贝一份给子进程，然后分配进程id给子进程；创建线程时，子线程与父进程是共享地址空间的，不存在大量的数据拷贝过程，所以线程间切换的资源消耗低于进程切换。

        创建进程和线程，在底层都是用的clone这个系统调用，区别是内核处理是传入的参数不同，主要实现在do_fork中，先为新进程分配内核空间和拷贝父进程的pcb，然后检查资源分配的有效性，设置pcb一些选项，区别开父子进程，设置状态阻塞子进程，分配新的pid，然后根据参数使用写时复制机制进行父子进程空间的拷贝或者直接共享地址空间。写时复制的效率也是远远低于直接共享的。

# 协程
    协程不是进程，也不是线程，它就是一个函数，一个特殊的函数——可以在某个地方挂起，并且可以重新在挂起处继续运行。所以说，协程与进程、线程相比，不是一个维度的概念。
    一个进程可以包含多个线程，一个线程也可以包含多个协程，也就是说，一个线程内可以有多个那样的特殊函数在运行。但是有一点，必须明确，一个线程内的多个协程的运行是串行的。如果有多核CPU的话，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内的多个协程却绝对串行的，无论有多少个CPU（核）。这个比较好理解，毕竟协程虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但是这些函数都是串行运行的。当一个协程运行时，其他协程必须挂起。
    当一个协程（特殊子进程）阻塞时，它可以切换到其他没有阻塞的协程上去继续执行，这样就能得到比较高的效率。（io密集型）

# 一个进程可以创建多少线程，和什么有关
    一个进程的虚拟地址空间是4G，用户可用2G,线程的（共享栈中的私有栈）栈大小为1M的话，最多能开2048个线程，就把内存资源消耗完毕了。
    进程开线程的数量和系统内存大小，默认栈空间大小有关。
    一个系统能开多少进程，也是受系统内存限制的，内存越大，最大进程数量越大。

# 一个程序从开始运行到结束的完整过程（四个过程）
    1、由操作系统将程序载入到内存中，同时那些不是存储在堆栈中的尚未初始化的变量将在此时得到初值
    2、启动程序和可执行程序连接在一起，接着便开始调用main函数
    3、代码开始执行 
    4、程序的最后一个阶段就是程序的终止，当然终止也分为”正常终止“和”非正常终止“，正常终止就是main函数返回，非正常终止可能由多种情况引起。 

# 进程通信方法（Linux和windows下），线程通信方法（Linux和windows下）
    进程通信：
        匿名管道：是一种特殊的文件，存在于内存中，半双工方式通信，数据只能单向流动，且只能用于亲缘关系的进程之间。创建管道后，自动打开fd[0]和fd[1]两个文件描述符，分别对应读操作和写操作。

        命名管道：与匿名管道不同，该文件存在于文件系统中，且无亲缘的进程之间也能使用，其他特性与匿名管道一致。

        消息队列：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

        共享内存：共享内存就是映射一段能被其他进程所访问的内存到内核中，这段共享内存由一个进程创建，但多个进程都可以通过内核映射区访问该段内存。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

        文件映射内存mmap：硬盘存储的一块空间映射到物理内存，然后操作这块物理内存就是在操作实际的硬盘空间，不需要经过内核态传递。比如你的硬盘上有一个文件，你可以使用linux系统提供的mmap接口，将这个文件映射到进程一块虚拟地址空间，这块空间会对应一块物理内存，当你读写这块物理空间的时候，就是在读取实际的磁盘文件，就是这么直接高效。通常诸如共享库的加载都是通过内存映射的方式加载到物理内存的。

            1、mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间进行映射。而shm共享内存，每个进程最终会映射到同一块物理内存。shm保存在物理内存，这样读写的速度肯定要比磁盘要快，但是存储量不是特别大。
        　　2、相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。
        　　3、另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget在内存里面就会丢失。
        　　4、总之，共享内存是在内存中创建空间，每个进程映射到此处。内存映射是创建一个文件，并且映射到每个进程开辟的空间中。

        信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

        本地套接字：建立socket本地套接字进行进程间通信。

        信号：通过内核发送信号给进程进行进程间通信。

            信号与信号量：
                信号：是由用户、系统或者进程发送给目标进程的信息，以通知目标进程某个状态的改变或系统异常。
                信号量：信号量是一个特殊的变量，它的本质是计数器，信号量里面记录了临界资源的数目，有多少数目，信号量的值就为多少，进程对其访问都是原子操作（pv操作，p：占用资源，v：释放资源）。它的作用就是，调协进程对共享资源的访问，让一个临界区同一时间只能有一个进程访问。

    线程通信：
        锁机制：包括互斥锁、条件变量、读写锁
            互斥锁提供了以排他方式防止数据结构被并发修改的方法。
            读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
            条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

        信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量

        信号机制(Signal)：类似进程间的信号处理（不建议使用）
    
    总结：线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

# 文件读写使用的系统调用
    int open(const char *pathname（文件名称）, int flags（标识位，文件操作方式）, mode_tmode（访问权限）);
    size_t read(int fd（文件描述符）, void *buf（存放读取的数据的缓冲区）, size_t count（读取字节数）);
    size_t write(int fd（文件描述符）, const void *buf（存放将要写入的数据的缓冲区）, size_t nbytes（写入字节数）);
    int close(int fd(文件描述符));

# 怎么回收线程
    线程的回收与线程的创建状态有关，对于非分离态的线程，在执行完毕后，由创建它的线程进行资源回收，pthread_join()函数返回成功则回收成功。对应分离状态的线程，程序执行完毕后，自动马上释放资源。

# 守护进程、僵尸进程和孤儿进程
    守护进程：守护进程是在后台运行不受终端控制的进程（如输入、输出等），一般的网络服务都是以守护进程的方式运行。

    僵尸进程：一个进程执行完毕后，他的父进程没有调用wait函数去回收资源，那么该进程就会变为一个僵尸进程。进程退出时会释放资源，但是pcb信息依旧存在，必须父进程回收资源才能被清理。如果存在大量僵尸进程将导致资源浪费，不能开启新的进程。
    
    孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成回收工作。

# 处理僵尸进程的两种经典方法
    父进程可调用wait函数回收其僵尸子进程
    杀死其父进程，使得僵尸进程变为孤儿进程，由init进程回收

# 进程终止的几种方式
    正常终止五种：
        1.从main返回。
        2.调用exit。
        3.调用_exit或_Exit。
        4.最后一个线程从其启动例程返回。
        5.最后一个线程调用pthread_exit。
    三种异常终止：
        6.调用abort()。
        7.接到一个信号并终止。
        8.最后一个线程对取消请求作出响应。

# linux中异常和中断的区别
    异常又叫同步中断，是当指令执行时由cpu控制单元产生的，之所以称之为异常，是因为只有在一条指令结束之后才发出中断（程序执行异常或者系统调用）。
　　中断又叫异步中断，是由其他硬件设备依照cpu时钟信号随机产生的。

# 一般情况下在Linux/windows平台下栈空间的大小
    linux默认8M（系统环境决定）:ulimit -s 32678，命令修改
    windows默认1M（编译器决定）:在vc++中可以修改默认栈空间的大小

# 程序从堆中动态分配内存时，虚拟内存上怎么操作的
    虚拟内存：理论上计算机处理器程序计数器的寻址范围（32位机器寻址范围位2^32,4GB）就是虚拟内存的大小，虚拟内存是一块逻辑地址空间，它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。在进程执行时，虚拟内存中的代码段在物理内存中切换执行，用户看来，好像是很大的内存。

    存储管理单元MMU:MMU通过页表将虚拟地址映射到物理地址（页表：存储虚拟地址与物理地址的映射关系）

    段页式管理：
        用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。
        用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。
        逻辑地址结构。一个逻辑地址用三个参数表示：段号S；页号P；页内地址d。
        段表、页表、段表地址寄存器。为了进行地址转换，系统为每个作业建立一个段表，并且要为该作业段表中的每一个段建立一个页表。系统中有一个段表地址寄存器来指出作业的段表起始地址和段表长度。

    虚拟内存管理：
        Linux把虚存空间分成若干个大小相等的存储分区，把这样的分区叫做页；为了换入、换出的方便，物理内存也就按也得大小分成若干个块，叫做页框。物理内存和虚拟内存被分成了页框与页之后，其存储单元原来的地址都被自然地分成了两段，高位段分别叫做页框码和页码，它们是识别页框和页的编码；低位段分别叫做页框偏移量和页内偏移量，它们是存储单元在页框和页内的地址编码。

        处理器遇到的地址都是虚拟地址。虚拟地址和物理地址都分成页码（页框码）和偏移值两部分。在由虚拟地址转化成物理地址的过程中，偏移值不变。而页码和页框码之间的映射就在一个映射记录表——页表中。

    请页与交换：
        当处理器试图访问一个虚存页面时，首先到页表中去查询该页是否已映射到物理页框中，并记录在页表中。如果在，则MMU会把页码转换成页框码，并加上虚拟地址提供的页内偏移量形成物理地址后去访问物理内存；如果不在，则意味着该虚存页面还没有被载入过内存，这时MMU就会通知操作系统：发生了一个缺页异常，启动所谓的“请页”机制，即调用相应的系统操作函数，判断该虚拟地址是否为有效地址。如果是有效的地址，就从虚拟内存中将该地址指向的页面读入到内存中的一个空闲页框中(伙伴系统算法)，并在页表中添加上相对应的表项，最后处理器将从发生页面错误的地方重新开始运行；如果是无效的地址，则表明进程在试图访问一个不存在的虚拟地址，此时操作系统将终止此次访问。

        在请页成功之后，内存中已没有空闲物理页框了。这是，系统必须启动所谓地“交换”机制，即调用相应的内核操作函数，在物理页框中寻找一个当前不再使用或者近期可能不会用到的页面所占据的页框。找到后，就把其中的页移出，以装载新的页面。对移出页面根据两种情况来处理：如果该页未被修改过，则删除它；如果该页曾经被修改过，则系统必须将该页写回辅存。

    LRU置换算法：
        Linux系统使用最近最少使用（LRU）页面的衰老算法。这种策略根据系统中每个页面被访问的频率，为物理页框中的页面设置了一个叫做年龄的属性。页面被访问的次数越多，则页面的年龄最小；相反，则越大。而年龄较大的页面就是待换出页面的最佳候选者。

    快表：
        系统一旦访问了某一个页，那么系统就会在一段时间内稳定地工作在这个页上。所以，为了提高访问页表的速度，系统还配备了一组正好能容纳一个页表的硬件寄存器，这样当系统再访问虚存时，就首先到这组硬件寄存器中去访问，系统速度就快多了。这组存放当前页表的寄存器叫做快表
    
    页面共享：
        相关程序的虚拟空间的页面在页表中指向内存中的同一个页框。

    页面保护：
        页表实际上是由虚拟空间转到物理空间的入口。因此，为了保护页面内容不被没有该页面访问权限的程序所破坏，就应在页表的表项中设置一些访问控制字段，用于指明对应页面中的内容允许何种操作，从而禁止非法访问。
    
    多级页表：
        有个页表4K,也会加载到物理内存，为了较少页表的开销，采用多级页表。、

    基本流程：
        虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2），而如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。

# 交换空间与虚拟内存的关系
    Linux 中的交换空间（Swap space）在物理内存（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去，所以交换空间作为虚拟内存的一部分。

# 堆区和栈区的区别
    1、栈区资源是由编译器分配释放的，内存的分配是连续的；堆区资源一般由程序员分配释放，内存分配不连续。
    2、栈区的空间是向上生长的，大小是由默认限制的；堆区是向下生长的，是不连续的区域，大小受虚拟空间大小限制，比栈区大，灵活。
    3、栈分配指令是CPU内置指令，分配效率高；堆区分配用效率低，且易产生内存碎片。
    4、栈中主要存储局部变量、上下文环境等，堆区主要存储用户变量；

# 内存泄漏和内存溢出
    程序申请内存后执行，在程序执行过程中，申请的内存一直无法释放，造成内存泄漏。一次两次的内存泄漏可能不会导致程序执行出错，但是内存泄漏随着程序执行时间变长，泄漏的内存积累到一定程度，导致程序无法申请新的内存造成内存溢出，程序报错。自己所需要使用的空间比我们拥有的内存大，内存不够使用所造成的内存溢出。
    自己申请的内存需要在其使用完毕后手动回收该内存，避免内存泄漏。使用内存检查工具来分析内存。

    1、在类的构造函数和析构函数中没有匹配的调用new和delete函数
    2、没有正确地清除嵌套的对象指针
    3、在释放对象数组时在delete中没有使用方括号
    4、指向对象的指针数组不等同于对象数组
    5、缺少拷贝构造函数
    6、缺少重载赋值运算符
    7、没有将基类的析构函数定义为虚函数

# 常见内存分配方式和错误
    分配方式：
        1、从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。
        2、在栈上分配。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。
        3、从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

    常见错误：
        1、内存分配未成功，却使用了它。
        2、内存分配虽然成功，但是尚未初始化就引用它。
        3、内存分配成功并且已经初始化，但操作越过了内存的边界。
        4、忘记了释放内存，造成内存泄露。
        5、释放了内存却继续使用它。

# 可重入函数和可重入内核
    可重入内核：若干个进程可以同时在内核态下执行，也就是说多个进程可以在内核态下并发执行内核代码。

    可重入函数：运行时只改变局部数据结构，不改变全局数据结构。首先它意味着这个函数可以被中断，其次意味着它除了使用自己栈上的变量以外不依赖于任何环境（包括 static），这样的函数就是purecode（纯代码）可重入，可以允许有该函数的多个副本在运行，由于它们使用的是分离的栈，所以不会互相干扰。
        1，不在函数内部使用静态或者全局数据
        2，不返回静态或者全局数据，所有的数据都由函数调用者提供
        3，使用本地数据，或者通过制作全局数据的本地拷贝来保护全局数据
        4，如果必须访问全局数据，使用互斥锁（自旋锁）来保护
        5，不调用不可重入函数
        6，可重入函数必须是线程安全的

    不可重入函数：运行该函数时也需要改变全局数据结构。

# 操作系统动态内存分配的几种策略
    首次适应算法：
        从空闲分区表的第一个表目查找，把最先找到的能够满足分配要求的空闲分区分配给作业，减少查找时间。
    最佳适应算法：
        遍历空闲分区，找出满足作业要求且最小的空闲分区，减少碎片。
    最差适应算法：
        遍历空闲分区，找出满足作业要求且最大的空闲分区，使链表节点大小趋于均匀。
    伙伴系统与slab：
        伙伴系统：
            把所有的空闲页框分组为块链表，每个块链表大小都是2的幂次方。
            假设进程要申请256个页框，先从块链表大小为256的链表中查找空闲块，若没有则去512的链表中查找，找到了则将512分为两个256的连续页框，一个分配出去，一个移动到大小为256的链表中。若512链表也没有找到，则向1024的链表找，没有找到则返回错误。页框释放时，将连续页框合并为更大的页框块
        这里给出伙伴的概念，满足以下三个条件的称为伙伴：
            1）两个块大小相同；
            2）两个块地址连续；
            3）两个块必须是同一个大块中分离出来的；
        伙伴系统缺点：
            1、两个空闲页框块中间有一个小的不空闲页框导致两个大的页框不能合并。
            2、伙伴系统内存分配为2的幂次方，若申请内存不是2的幂次方将造成内存浪费（内部碎片）
            3、链表合并与拆分开销较大
    slab机制:
        slab是Linux操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的小对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。 

    Linux 的slab 可有三种状态：
         满的：slab 中的所有对象被标记为使用。
         空的：slab 中的所有对象被标记为空闲。
         部分：slab 中的对象有的被标记为使用，有的被标记为空闲。
        slab 分配器首先从部分空闲的slab 进行分配。如没有，则从空的slab 进行分配。如没有，则从物理连续页上分配新的slab，并把它赋给一个cache ，然后再从新slab 分配空间。

    与传统的内存管理模式相比， slab 缓存分配器提供了很多优点。
        1、内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。
        2、slab 缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。
        3、slab 分配器还支持通用对象的初始化，从而避免了为同一目的而对一个对象重复进行初始化。
        4、slab 分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。

# 内部碎片和外部碎片
    单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。

    内部碎片：
        系统给一个进程分配了一个页面，但是进程使用了页面的一部分，另一部分没有使用，由于该进程占有这个页面，系统也无法再利用，直到进程释放该页面。
        因为所有的内存分配必须起始于可被 4、8 或 16 整除（视处理器体系结构而定）的地址或者因为MMU的分页机制的限制，决定内存分配算法仅能把预定大小的内存块分配给客户。假设当某个客户请求一个 43 字节的内存块时，因为没有适合大小的内存，所以它可能会获得 44字节、48字节等稍大一点的字节，因此由所需大小四舍五入而产生的多余空间就叫内部碎片。
    外部碎片：
        频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。假设有一块一共有100个单位的连续空闲内存空间，范围是0~99。如果你从中申请一块内存，如10个单位，那么申请出来的内存块就为0~9区间。这时候你继续申请一块内存，比如说5个单位大，第二块得到的内存块就应该为10~14区间。如果你把第一块内存块释放，然后再申请一块大于10个单位的内存块，比如说20个单位。因为刚被释放的内存块不能满足新的请求，所以只能从15开始分配出20个单位的内存块。现在整个内存空间的状态是0~9空闲，10~14被占用，15~24被占用，25~99空闲。其中0~9就是一个内存碎片了。如果10~14一直被占用，而以后申请的空间都大于10个单位，那么0~9就永远用不上了，变成外部碎片。
        频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，这些小页面无法再满足分配需求而无法利用。
    
    通过调整进程占用的分区位置来减少或避免分区碎片：
        紧凑(compaction) 通过移动分配给进程的内存分区，以合并外部碎片。紧凑的条件是：所有的应用程序可动态重定位。
        分区对换(Swapping in/out) 通过抢占并回收处于等待状态进程的分区，以增大可用内存空间。

# 系统调用进入内核态的过程
    系统调用：系统调用是操作系统为用户提供的一系列API；系统调用将用户的请求发给内核，内核执行完以后，将结果返回给用户；

    过程：
        用户程序调用c库write（）函数 -> 将参数存入寄存器（用户栈与内核栈无法直接交换数据），调用）0X80陷入指令 -> 找到中断处理程序system_call（），将参数信息压入内核栈，根据系统调用号查找系统调用表，找到系统调用程序入口开始执行系统调用 -> 系统调用执行完毕，调用ret_from_sys_call(),恢复用户栈，返回用户程序。

# 内核态和用户态的区别
    操作系统为了集中管理有限资源，防止使用冲突，避免用户的危险操作，将CPU设置了四个特权级别0~3，在Linux下使用了0和3两个级别，不同级别的CPU执行不同指令。
    操作系统启动时，对物理内存进行了划分，分为用户空间和内核空间，用户态程序只能访问用户空间，内核态两个空间都能访问。当一个进程陷入内核时，该进程进入内核态，CPU级别变为最高级别，使用内核栈执行内核代码，进程退出内核态，执行用户代码，处理器变为最低级别。用户态切换到内核态可以通过：系统调用；异常；中断这三种主要的方式。

# 常见的进程调度算法，Linux使用的调度机制
    常见进程调度算法：
        先来先服务：
            进程先来就先获得处理器时间，用一个队列暂存等待处理的进程，按先后顺序执行进程。（紧急进程无法快速处理）
        短作业优先：
            设置执行时间短的进程作业优先级高，优先级高的进程先执行。（一直有短作业到来，饿死长进程）
        最短剩余时间：
            设置执行剩余时间短的进程作业优先级高，优先级高的进程先执行。
        *上述均存在饥饿现象。
        时间片轮转：
            进程作业维护一个环形队列，让每一个进程都上CPU执行一段时间。（紧急进程无法快速处理）
        最高响应比优先：
            进程从加入等待队列开始一直到执行完毕经历的时间除以进程使用处理器的时间，这个响应比比较高的就证明该进程等待比较久了，它估计会很饿，先让它执行。

    Linux进程调度机制：
        CFS(完全公平调度) ：Linux的CFS调度器没有直接分配时间片到进程，而是分配处理器的使用比。这样进程所获得的处理器时间其实是和系统负载密切相关的，这个比例进一步还会受进程nice值（优先级）影响。具有更小nice值的进程会被赋予高权重，从而有用更多的处理器使用比。CFS在所有可运行总数基础上计算出一个进程应该运行多久的时间。允许每个进程运行一段时间，循环轮转，选择运行最少的进程作为下一个运行进程。每个进程都按其权重在全部可运行进程中所占比例的“时间片”来运行。当运行进程数量很大时，为避免频繁的切换消耗，CFS设置了底线。每个进程时间片的最小粒度是1ms，也就是说就算进程数量无限大，每个最少也能获得1ms的运行时间。CFS 维护了一个以时间为顺序的红黑树。

        cfs定义了一种新的模型，其基本思路很简单，他把CPU当做一种资源，并记录下每一个进程对该资源使用的情况，在调度时，调度器总是选择消耗资源最少的进程来运行。这就是所谓的“完全公平”。但这种绝对的公平有时也是一种不公平，因为有些进程的工作比其他进程更重要，我们希望能按照权重来分配CPU资源。权重越高，使用比越低，越先被执行。

# 中断、陷阱、故障和终止
    中断：
        异步发生的，来自处理器外部IO设备的信号（区别于同步异常：执行一条指令的结果），它不是由任何一条专门的指令造成的。例如网络适配器、磁盘控制器通过向处理器芯片上的一个管脚发信号，并将异常号放在系统总线上，来触发中断，这个异常号标识了引起中断的设备。中断处理程序总是返回到当前指令的下一条指令
    异常：
        异常又叫同步中断，是当指令执行时由cpu控制单元产生的。
        陷阱：
    　　    陷阱是同步发生的，是执行一条指令的结果。陷阱最重要的用途是在用户程序和内核之间提供系统调用接口。陷阱总返回到当前指令的下一条指令。
        故障：
            故障由错误引起，它可能被故障处理程序修正，如果修正成功，将返回到当前正在执行的指令，重新执行。否则处理程序返回到内核的abort历程，将终止故障程序。故障的一个典型是缺页异常。
        终止：
            由不可恢复的致命错误造成的结果，处理程序将返回到内核中的abort例程，终止应用程序。

        内核为每个进程维护了一个上下文。上下文就是内核重新启动一个被抢占进程所需要的状态集：通用寄存器，浮点寄存器，程序计数器，用户栈，状态寄存器，内核栈和各种内核数据结构（比如也表，进程表，文件表等）。内核通过调度器来抢占一个执行的进程：
        （1）保护当前进程的上下文
        （2）恢复某个先前被抢占进程所保存的上下文
        （3）将控制传递给新恢复的进程。

# 内存对齐的规则和作用
    规则：
        1、对于结构体的各个成员，第一个成员位于偏移为0的位置，以后每个数据成员的偏移量必须是 min(#pragma pack()指定的数，这个数据成员的自身长度) 的倍数。
        2、在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行对齐。
    作用：
        1、平台原因(移植原因)：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
        2、性能原因：经过内存对齐后，CPU的内存访问速度大大提升。具体原因稍后解释。

    总结：
        结构体的内存对齐是拿空间来换取时间的做法（不对齐需要多次寻址取出数据，效率低下）
        那在设计结构体的时候，我们既要满足对齐，又要节省空间：让占用空间小的成员尽量集中在一起。

# 页面置换算法
    最佳置换算法：
        将未来最久不使用的页面替换出去（无法实现，作为衡量基准）
    最近不常使用置换算法：
        给每个页一个标志位，R标识最近被访问过，M标识最近被修改过，定时对R清零。首选置换出R=0的页，其次R=1，其次M=0,最后R=1，M=1。
    先进先出置换算法：
        置换出在内存中存在最久的页。近似随机淘汰
    改进的先进先出置换算法：
        在FIFO的基础上，给页面增加标志位R,最近使用过该页则R置1，页面遇到R=1的页面先置零，遇到R=0的页面直接淘汰。
    时钟置换算法：
        在改进的FIFO算法的基础上，将页面队列首尾相连，形成环形队列，当发生缺页异常时，从当前位置寻找R=0的页淘汰，R=1的页置零。
    最久未使用置换算法（LRU）:
        置换出最近最久未使用的页面。性能较好。

# 线程互斥和同步的方法
    互斥：互斥量、读写锁、自旋锁
        是指散步在不同任务之间的若干程序片断，当某个任务运行其中一个程序片段时，其它任务就不能运行它们之中的任一程序片段，只能等到该任务运行完这个程序片段后才可以运行。最基本的场景就是：一个公共资源同一时刻只能被一个进程或线程使用，多个进程或线程不能同时使用公共资源。
            互斥锁：
                互斥锁是一种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态,即上锁( lock )和解锁( unlock )，同一时刻只能有一个程序片段访问该加锁资源。
            读写锁：
                如果某线程申请了读锁，其它线程可以再申请读锁，但不能申请写锁。
                如果某线程申请了写锁，其它线程不能申请读锁，也不能申请写锁。
            自旋锁：
                自旋锁与互斥量功能一样，唯一一点不同的就是互斥量阻塞后休眠让出cpu，而自旋锁阻塞后不会让出cpu，会一直忙等待，直到得到锁。（死锁，资源浪费）
            
    同步：轮询结合互斥量、条件变量、信号量、屏障
        是指散步在不同任务之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。最基本的场景就是：两个或两个以上的进程或线程在运行过程中协同步调，按预定的先后次序运行。比如 A 任务的运行依赖于 B 任务产生的数据。

            条件变量：
                条件变量是用来等待而不是用来上锁的。条件变量用来自动阻塞一个线程，直到某特殊情况发生为止。通常条件变量和互斥锁同时使用。（避免无谓的加锁和解锁）
                条件变量使我们可以睡眠等待某种条件出现。条件变量是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待"条件变量的条件成立"而挂起；另一个线程使“条件成立”（给出条件成立信号）。
            信号量：
                信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问。操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值大于 0 时，则可以访问，否则将阻塞。PV 原语是对信号量的操作，一次 P 操作使信号量减１，一次 V 操作使信号量加１。
            屏障：
                屏障是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有合作的线程都到达某一个点时，然后从该点继续执行。pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出。屏障对象的概念就更加广泛了，他们允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不用退出。所有的线程到达屏障以后可以接着工作。

                屏障的应用之一：
                比如说，现在有800万个数据要进行排序。现在创建出9个线程，一个主线程和8个工作线程。每个工作线程分别对100万个数据进行堆排序，主线程中设置屏障，等待八个线程完成数据的排序后，对八个线程排好序的八组数据在进行归并排序。在8核的系统中，单线程程序对800万个数进行排序需要12.14秒。同样的系统，使用8个并行线程和一个合并线程处理相同的800万个数排序仅仅只需要1.91秒，速度提高了6倍。

# 多线程交替打印奇数偶数
    #include <thread>
    #include <iostream>
    #include <mutex>
    #include <condition_variable>
    std::mutex data_mutex;
    std::condition_variable data_var;
    bool label = false;
    
    void printodd()
    {
        std::unique_lock<std::mutex> ulock(data_mutex);
        for (int odd = 1; odd <= 100; odd += 2)
        {
            data_var.wait(ulock, [] {return label; });
            std::cout << std::this_thread::get_id() << ": " << odd << " labelA= "<<label<<std::endl;
            label = false;
            data_var.notify_one();
        }
    }
    
    void printeven()
    {
        std::unique_lock<std::mutex> ulock(data_mutex);
        for (int even = 0; even < 100; even += 2)
        {
            std::cout << std::this_thread::get_id() << ": " << even << " labelB= " << label<< std::endl;
            data_var.notify_one();
            label = true;
            data_var.wait(ulock, [] {return !label; });
        }
    }
    
    int main()
    {
        std::thread t1(printeven);
        std::thread t2(printodd);
        t1.join();
        t2.join();
        std::cout << "end!" << std::endl;
        getchar();
        return 0;
    }

# 死锁的必要条件（怎么检测死锁，解决死锁问题）,银行家算法（死锁避免）
    死锁是指两个或两个以上的进程（线程）在运行过程中竞争资源，但是又都获取不到资源的状态，若无外力作用，这些进程（线程）都将无法向前推进。

    必要条件：
        1、互斥条件，进程竞争的资源具有排他性，一段时间内只能被一个进程所使用
        2、不可剥夺条件：进程获取的资源不能被其他进程夺走，只能自己释放
        3、请求与保持条件：进程已经持有资源，此时请求新的的资源，新资源被其他进程占有，进程获取不到资源而阻塞，但是不释放已持有资源
        4、循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。

    处理死锁：
        预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的发生。
        避免死锁：在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免死锁的发生。
        检测死锁：允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。
        解除死锁：当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。

    死锁检测：资源分配图
        如果分配图没有环，那么系统就没有进程死锁，如果分配图有环，那么可能存在死锁。
        当且仅当S状态的资源分配图是不可完全简化的时候，系统状态则是死锁状态

    死锁解除：
        撤消所有的死锁进程
        连续撤消死锁进程直至不再存在死锁
        连续剥夺资源直到不再存在死锁
        把每个死锁进程备份到前面定义的某个检查点，并重新启动所有进程

    死锁避免：
        1、判断“系统安全状态”法
            在进行系统资源分配之前，先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，让进程等待。 

        2、银行家算法
            安全序列：假设银行有100亿，分别贷款给企业A，B，C，（A最终需要70亿、B最终需要40亿、C最终需要50亿），如果银行不能满足企业的最终需求，那么之前贷出的钱就收不回来，所以必须存在满足所有企业最终需求的贷款序列，才是安全状态，否则是不安全状态。比如，ABC分别贷款20/10/30亿，A再贷款30亿，那么银行还剩10亿，而ABC分别还需要20/30/20亿，都不能满足，那么银行进入不安全状态。若B再贷10亿，那么ABC分别还需要50/20/20亿，银行还剩30亿，满足BC的需求，贷给BC后，BC还款，贷给A，完成此次所有贷款，这既是一个安全序列。

            核心思想：（剩余可用资源 vs 申请资源 满足则加入安全序列，不满足则阻塞等待，比较下一个请求）
                在资源分配之前预判这次分配会不会导致系统进入不安全状态，依据状态来决定是否分配资源给该请求。（多种资源：向量表示）
        
        银行家算法步骤：
            1、检查此次申请是否超过了之前声明的最大需求数
            2、检查此时系统剩余可用资源是否能满足此次请求
            3、试探着分配
            4、使用安全性算法检查此次分配是否会导致系统进入不安全状态

        安全性算法步骤：
            1、检查当前剩余可用资源是否能满足某个进程的最大需求，可以则将该进程加入安全序列，并把该进程资源回收，不断重复上述过程，看最终能否让所有进程都加入安全序列。
      
# 哲学家就餐问题及解决方案
    五个哲学家围在一张圆形桌上吃饭，每个哲学家左边和右边分别放置一根筷子，哲学家只有在拿到左右两支筷子时才能吃饭，吃完饭放下筷子。假设五个哲学家同时拿起左手边的筷子，然后去申请右手边的筷子，这时每个哲学家都握有左手的筷子，而右手的筷子获取不到，造成无限等待。

    信号量解决方案：
        N个进程并发执行，进程需要2个某类系统资源，如果系统提供N+1个同类资源，则一定不会发生死锁（鸽笼原理）；
        N个进程并发执行，进程需要R个某类资源，如果系统提供K=N*（R-1）+1个同类资源，则一定不会发生死锁。
        基于上述两个结论：计算出该资源数量下不会死锁的进程数，用信号量控制合理的进程数量并发执行。

    回退机制解决方案：
        预防死锁是指通过设置某些限制条件 ,去破坏产生死锁的 4 个必要条件中的一个或几个来防止死锁的发生. 其中“摒弃不剥夺条件”规定,当一个进程提出新的资源请求而不能立即得到满足时 ,必须释放其已经保持了的所有资源 , 即已经占有的资源可以被剥夺。
        基于以上结论：每位哲学家申请左手边的筷子后，去申请右手边的筷子，哲学家i和右手边的哲学家比较谁获得左手筷子的时间更晚，更晚的回退左手筷子，直到有哲学家能获得两支筷子为止。

    附加规则解决方案：
        破坏了死锁生的必要条件之一：“环路等待”条件，从而有效地预防了死锁的产生。
        基于以上结论：添加一条竞争规则：所有哲学家先竞争奇数号筷子，获得后才能去竞争偶数号筷子（由于5号哲学家左右都是奇数号筷子，在本文中规定他先竞争5号筷子）。这样的话就总会有一名哲学家可以顺利获得两支筷子开始进餐。此方法的本质是通过附加的规则，让哲学家按照一定的顺序请求临界资源——筷子，避免了环路等待。

# 生产者消费者（怎么加锁解锁，伪代码）
    #include <thread>
    #include <mutex>
    #include <deque>
    #include <vector>
    #include <condition_variable>
    #include<ctime>
    #include<iostream>
    using namespace std;
    class demo
    {
    private:
        deque<int> data;
        mutex d_mutex;
        condition_variable m_m;

        int m_n;
    public:

        demo()
        {
            data.clear();
            m_n = 0;
        }
        void product()
        {
            srand(time(0));
            while (true)
            {
                unique_lock<mutex> lck(d_mutex);
                m_m.wait(lck, [this]() {return data.size() <= 10; });
                m_n = rand() % 1000;
                cout << m_n << " producted!!!" << endl;
                data.push_back(m_n);
                m_m.notify_all();
            }
        }
        void consuem()
        {
            while (true)
            {
                unique_lock<mutex> lck(d_mutex);
                while (data.empty())
                {
                    m_m.wait(lck, [this]() {return data.size() > 0; });
                }
                int tmp = data.front();
                cout << tmp << "  consuemed!!!" << endl;
                data.pop_front();
                m_m.notify_all();
            }
        }
        void start()
        {
            thread t1(&demo::product,this);
            thread t2(&demo::consuem,this);
            t1.join();
            t2.join();
        }
    };
    int main()
    {
        demo test;
        test.start();
        system("pause");
        return 0;
    }

# 实现一个LRU页置换算法（或者FIFO置换算法）
    class LRUCache
    {
        private:
            list<pair<int,int>> cache;
            unordered_map<int, list<pair<int,int>>::iterator> map;
            int cap;
        public:
            LRUCache(int capacity) {
                this->cap = capacity;
            }
            int get(int key) {
                if(map.find(key) == map.end())
                {
                    return -1;
                }else
                {
                    pair<int,int> kv = *map[key];
                    cache.erase(map[key]);
                    cache.push_front(kv);
                    map[key] = cache.begin();
                    return kv.second;
                }
            }
            void put(int key, int value) {
                if(map.find(key) == map.end())
                {
                    if(cache.size() == cap)
                    {
                        map.erase(cache.back().first);
                        cache.pop_back();
                    }
                    cache.push_front(make_pair(key,value));
                    map[key] = cache.begin();
                }
                else
                {
                    cache.erase(map[key]);
                    cache.push_front(make_pair(key, value));
                    map[key] = cache.begin();
                }
            }
    };

# 父子进程共享
    读时共享、写时复制
        两个地址空间单独存在，进程间不共享改变的数据

    用户空间相同：
        父进程fork出一个子进程，为子进程分配有个新的地址空间，该地址空间的用户空间在读数据时，直接映射的物理内存与父进程映射的内存是同一块，当发生数据写时，子进程映射到一块新的内存区域，将原区域的数据拷贝到新区域，供子进程读写。

    内核空间不同：
        PCB控制块、定时器、未决信号集等。

# exec工作原理
    换核不换壳
        当进程调用exec函数时，该进程的用户空间代码和数据被新程序替换，从新程序的历程执行，并不创建新进程。

# 回收子进程
    wait(int* status)阻塞回收
        status是传出参数，通过另外几个宏函数处理status可以知道子进程的死亡原因（正常、异常）（多个子进程循环回收）
    waitpid(size_t pid,int* status,int options)可非阻塞回收
        pid取值可以选择回收范围，options可以选择回收阻塞与否（多个子进程循环回收）

# 悲观锁与乐观锁
    悲观锁：（多写）
        总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。

    乐观锁：（多读）
        总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。

        实现方式：
            版本号机制：
                一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

            CAS算法：compare and swap
                是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步。设置三个操作数，需要读写的内存值V，进行比较的值A，拟写入的新值B，当且仅当V==A，通过原子方式用B更新V，自旋重试直到操作成功。
        
        缺点：
            ABA问题：
                如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。
            自旋开销大：
            只能保证一个共享变量的原子操作：
                


    









