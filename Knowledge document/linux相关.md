# Linux的I/O模型介绍以及同步异步阻塞非阻塞的区别（超级重要）
    对于套接字的输入，第一步是等待数据从网络中到达，当所等待的数据到达时，数据被复制到内核中的缓冲区。第二步则是把数据从内核缓冲区复制到应用进程的缓冲区。 
    根据在这两个不同阶段处理的不同，可以将I/O模型划分为以下五种类型：

        阻塞IO:
            应用进程调用IO函数，然后切换到内核空间中运行，直到数据报到达且被复制到应用进程缓冲区中才返回。我们说进程从调用IO函数开始到它返回的整段时间内是被阻塞的。函数成功返回后，应用进程开始处理数据报。
        非阻塞IO：
            应用进程调用IO函数，然后切换到内核空间运行，内核数据未准备好，立即返回应用程序一个调用错误，循环的调用该IO函数检测数据是否准备好，直到内核数据准备好，拷贝到用户空间，返回成功。进程轮询检查期间，消耗大量CPU。
        IO复用：
            应用进程阻塞，但是IO复用可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。
        信号驱动IO：
            用户程序需要等待数据的时候，注册一个信号处理函数告诉内核我需要数据，然后不等待数据准备好继续执行并不阻塞。当数据准备好时，用户程序会收到内核发送的SIGIO信号，在信号处理函数中调用I/O操作函数处理数据（数据在调用io操作函数后从内核空间拷贝到用户空间）。
        异步IO：
            应用程序告诉内核需要什么数据，然后继续执行用户程序，当内核将数据拷贝至用户空间时告诉进程数据已准备好，内核会产生一个信号通知应用进程，应用进程对数据报进行处理。

# 文件系统的理解（EXT4，XFS，BTRFS）
    

# 文件处理grep,awk,sed这三个命令必知必会
    正则：
        ^    #锚定行的开始 如：'^grep'匹配所有以grep开头的行。    
        $    #锚定行的结束 如：'grep$'匹配所有以grep结尾的行。 
        .    #匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。

        *    #匹配零个或多个先前字符 如：'*grep'匹配所有一个或多个空格后紧跟grep的行。  
        .*   #一起用代表任意字符。   
        []   #匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。    
        [^]  #匹配一个不在指定范围内的字符
        \(..\)  #标记匹配字符，如'\(love\)'，love被标记为1。    
        \<      #锚定单词的开始，如:'\<grep'匹配包含以grep开头的单词的行。    
        \>      #锚定单词的结束，如'grep\>'匹配包含以grep结尾的单词的行。    
        x\{m\}  #重复字符x，m次，如：'0\{5\}'匹配包含5个0的行。    
        x\{m,\} #重复字符x,至少m次，如：'o\{5,\}'匹配至少有5个o的行。    
        x\{m,n\}#重复字符x，至少m次，不多于n次，如：'o\{5,10\}'匹配5--10个o的行。   
        \w    #匹配文字和数字字符，也就是[A-Za-z0-9]，
        \W    #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。   
        \b    #单词锁定符，如: '\bgrep\b'只匹配grep。 

    grep:文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来
        格式：grep [OPTIONS] PATTERN [FILE...]
        参数：
            -n  打印行号
                grep -n ".*" h.txt        所有打印行号
                grep -n "root" h.txt    匹配的内容显示行号
            -v  不包括
            -E  表示过滤 多个参数
                grep -Ev "sshd|network|crond|sysstat|"
            -o:仅打印你需要的东西，默认打印正行
                grep -o "hello" h.txt
            -i:忽略大小写
                grep -i "hello" h.txt
            -c: 用于统计文中出现的次数
            --color=auto  过滤字段添加颜色
                利用正则打印特定字符
            \b：作为边界符，边界只包含特定字符的行
                grep "\boldboy\b" /etc/passwd   -->只过滤包含oldboy的行
        实例：
            显示所有以d开头的文件中包含test的行：grep -n 'test' d* 
            显示所有包含每个字符串至少有5个连续小写字符的字符串的行:grep -n '[a-z]\{5\}' filename

    sed:逐行处理文件（或输入），并将输出结果发送到屏幕。 sed 的命令就是在 vi和 ed/ex 编辑器中见到的那些。 sed 把当前正在处理的行保存在一个临时缓存区中，这个缓存区称为模式空间或临时缓冲。sed 处理完模式空间中的行后（即在该行上执行 sed 命令后），就把改行发送到屏幕上（除非之前有命令删除这一行或取消打印操作）。 sed 每处理完输入文件的最后一行后， sed 便结束运行。 sed 把每一行都存在临时缓存区中，对这个副本进行编辑，所以不会修改或破坏源文件。
        格式：sed [选项] ‘ command’ 输入文本

            选项	说明
            -n	使用安静模式，在一般情况所有的 STDIN 都会输出到屏幕上，加入-n 后只打印
            被 sed 特殊处理的行
            -e	多重编辑，且命令顺序会影响结果
            -f	指定一个 sed 脚本文件到命令行执行，
            -r	Sed 使用扩展正则
            -i	直接修改文档读取的内容，不在屏幕上输出

        实例：
            p命令：sed -n '/north/p' ceshi.txt  打印
            d命令：sed -n '3d' ceshi.txt        删除
                   sed '3,$d' ceshi.txt
            s命令：sed 's/west/north/g' ceshi.txt 替换
                  sed -n 's/^west/north/p' ceshi.txt 
                  sed 's/\(Mar\)got/\1linanne/p' ceshi.txt 包含在圆括号里的模式 Mar 作为标签 1 保存在特定的寄存器中。替换串可以通过\1 来引用它。则 Margot 被替换为 Marlinane。
            
            指定行的范围：逗号：sed -n '/west/,/east/p' ceshi.txt
            多重编辑： e 命令：sed -e '1,3d' -e 's/Hemenway/Jones/' ceshi.txt
            追加： a 命令：sed '/^north/a Hello world!' ceshi.txt 
            插入： i 命令：sed '/eastern/i Hello,world!\
            修改： c 命令：sed '/eastern/c Hello,world! \

            sed 's/^[ ]*//' sed.txt//删除行首的空格
            sed 's/^[0-9][0-9]*//g' sed.txt//删除行首数字
        

        awk:把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。
            格式：awk 'BEGIN{ commands } pattern{ commands } END{ commands }'

                -F fs or –field-separator fs 
                指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:

                -v var=value or –asign var=value 
                赋值一个用户定义变量。
                -f scripfile or –file scriptfile 
                从脚本文件中读取awk命令。

                -mf nnn and -mr nnn 
                对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。

                -W compact or –compat, -W traditional or –traditional 
                在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。

                -W copyleft or –copyleft, -W copyright or –copyright 
                打印简短的版权信息。

                -W help or –help, -W usage or –usage 
                打印全部awk选项和每个选项的简短说明。

                -W lint or –lint 
                打印不能向传统unix平台移植的结构的警告。

                -W lint-old or –lint-old 
                打印关于不能向传统unix平台移植的结构的警告。

                -W posix 
                打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符和=不能代替^和^=；fflush无效。

                -W re-interval or –re-inerval 
                允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。

                -W source program-text or –source program-text 
                使用program-text作为源代码，可与-f命令混用。

                -W version or –version 
                打印bug报告信息的版本。

            实例：
                每行按空格或TAB分割（默认情况），输出文本中的1、4项
                $ awk '{print $1,$4}' log.txt

                每行按,分割，输出文本中的1、2项
                awk -F, '{print $1,$2}'   log.txt

                使用多个分隔符.先使用空格分割，然后对分割结果再使用","分割
                awk -F '[ ,]'  '{print $1,$2,$5}'   log.txt

                过滤第一列大于2的行
                awk '$1>2' log.txt

                过滤第一列大于2并且第二列等于’Are’的行
                awk '$1>2 && $2=="Are" {print $1,$2,$3}' log.txt

                输出第二列包含 "th"，并打印第二列与第四列
                awk '$2 ~ /th/ {print $2,$4}' log.txt

                ·    $ awk '{print $3}'test-----截取第三域(列)的内容。

                ·    $ awk '/^(no|so)/'test-----打印所有以模式no或so开头的行。

                ·    $ awk '/^[ns]/{print$1}' test-----如果记录以n或s开头，就打印这个记录。

                ·    $ awk '$1~/[0-9][0-9]$/(print $1}' test-----如果第一个域以两个数字结束就打印这个记录。

                ·    $ awk '$1 == 100 || $2< 50' test-----如果第一个或等于100或者第二个域小于50，则打印该行。

                ·    $ awk '$1 != 10'test-----如果第一个域不等于10就打印该行。

                ·    $ awk '/test/{print $1 +10}' test-----如果记录包含正则表达式test，则第一个域加10并打印出来。

                ·    $ awk '{print ($1 > 5? "ok "$1: "error"$1)}' test-----如果第一个域大于5则打印问号后面的表达式值，否则打印冒号后面的表达式值。

                ·    $ awk '/^root/,/^mysql/'test----打印以正则表达式root开头的记录到以正则表达式mysql开头的记录范围内的所有记录。如果找到一个新的正则表达式root开头的记录，则继续打印直到下一个以正

            常用内建变量：
                FNR                浏览文件的记录数
                FS                 设置输入域分隔符，等价于命令行 -F选项
                NF                 浏览记录的域的个数
                NR                 已读的记录数

# IO复用的三种方法（select,poll,epoll）深入理解，包括三者区别，内部原理实现？
    IO多路复用：内核提供的一种同时监控多个文件描述符状态的机制。
    水平触发：是默认/缺省的工作方式，同时支持 block和no_block socket。这种工作方式下，内核会通知你一个fd是否就绪，然后才可以对这个就绪的fd进行I/O操作。就算你没有任何操作，系统还是会继续提示fd已经就绪，不过这种工作方式出错会比较小，传统的select/poll就是这种工作方式的代表。

    边沿触发：是高速工作方式，仅支持no_block socket，这种工作方式下，当fd从未就绪变为就绪时，内核会通知fd已经就绪，并且内核认为你知道该fd已经就绪，不会再次通知了，除非因为某些操作导致fd就绪状态发生变化。如果一直不对这个fd进行I/O操作，导致fd变为未就绪时，内核同样不会发送更多的通知，因为only once。所以这种方式下，出错率比较高，需要增加一些检测程序。
    ET模式下每次write或read需要循环write或read直到返回EAGAIN错误。以读操作为例，这是因为ET模式只在socket描述符状态发生变化时才触发事件，如果不一次把socket内核缓冲区的数据读完，会导致socket内核缓冲区中即使还有一部分数据，该socket的可读事件也不会被触发,根据上面的讨论，若ET模式下使用阻塞IO，则程序一定会阻塞在最后一次write或read操作，因此说ET模式下一定要使用非阻塞IO。

    LT可以理解为水平触发，只要有数据可以读，不管怎样都会通知。而ET为边缘触发，只有状态发生变化时才会通知，可以理解为电平变化

    select模型：
        函数原型：int select(int nfds（需要监视的文件描述符最大值+1）, fd_set *readfds（需要检测的可读文件描述符集合）, fd_set *writefds（需要检测的可写文件描述符集合）,fd_set *exceptfds（需要检测的异常文件描述符集合）, struct timeval *timeout（超时时间）);-1失败，0超时，成功>0
        工作流程：初始化fd_set（位图）->将需要监听的套接字加入集合->调用select函数监听描述符，将fd_set拷贝到内核空间，轮询检测数据，将改变的fd_set从内核空间拷贝到用户空间，函数返回->用fd_isset()遍历检测返回的集合中有那些套接字数据准备好->处理数据->
        备注：select模型的检测集合是三个位图，需要轮序检测，默认大小为1024，每次检测返回的所有的数据集合，需要遍历集合去检测具体是哪些文件描述符有数据到来，所以时间复杂度是O(N)的，监听的套接字越多，效率就越低。突破1024的限制，在Windows下可以修改1024的宏，在Linux下需要重新编译内核或者多线程监听，实现线程数*1024。最大特点：跨平台。
    
    poll模型：
        poll模型相对于select模型突破了1024的限制，使用pollfd结构描述集合，将三个描述信息整合到一个结构体中，通过设置事件和事件掩码得到相应事件，采用数组保存多个结构体监听多个文件描述符。
        函数原型：
            int poll (struct pollfd *fds（结构体数组，保存文件描述符）, unsigned int nfds（结构体数组大小+1）, int timeout(超时时间));
            备注：poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

        select/poll的缺点在于：
            1、效率问题：每次进行select调用都会线性扫描全部的fd集合。这样，效率就会呈现线性下降。
            2、内核/用户空间内存拷贝问题：select在解决将fd消息传递给用户空间时采用了内存拷贝的方式。这样，其处理效率不高。
            3、每次在调用开始时，要把当前进程放入各个文件描述符的等待队列。在调用结束后，又把进程从各个等待队列中删除，需要重新维护监控集合。

    epoll模型：
        epoll是为处理大批量句柄而做了改进的poll。
        函数原型：
            int epoll_create(int size);//创建epoll句柄fd，该fd应在epoll使用完成关闭，否则会导致fd耗尽。size参数被忽略。
            int epoll_ctl(int epfd（epoll句柄）, int events(动作类型：添加、修改、删除), int fd（需要监听的fd）, struct epoll_event *event（事件类型）);//epoll的事件注册函数，它不同于select是在监听事件时告诉内核要监听什么类型的事件，而是通过epoll_ctl注册要监听的事件类型。（将新的套接字挂到红黑树上，指明动作类型和事件类型）
            int epoll_wait(int epfd(epoll句柄), struct epoll_event *events（内核把发生的事件赋值到该数组））, int maxevents（events数组的大小）, int timeout（超时时间）);
            
            高效性：
                执行epoll_create时，创建了红黑树和就绪list链表；套接字fd会以红黑树的形式保存在内核cache里（slab机制），以支持快速查找、插入和删除。
                执行epoll_ctl时，如果增加fd，则检查在红黑树中是否存在，存在则立即返回，不存在则添加到红黑树中，然后向内核注册回调函数，用于当中断事件到来时向准备就绪的list链表中插入数据。epoll_ctl不需要每次都拷贝所有的fd列表，只需要进行增量式操作。因此，在调用epoll_create函数之后，内核已经在内核开始准备数据结构用于存放需要监控的fd了。其后，每次epoll_ctl只是对这个数据结构进行简单的维护操作即可。

                执行epoll_wait时立即返回准备就绪链表里的数据即可。每次调用epoll_wait，其仅需要从内核态复制少量的fd到用户空间而已。那么，这个准备就绪的list链表是怎么维护的呢？过程如下：当我们执行epoll_ctl时，除了把fd放入到epoll文件系统里file对象对应的红黑树之外，还会给内核中断处理程序注册一个回调函数，其告诉内核，如果这个fd的中断到了，就把它放到准备就绪的list链表中。

# Epoll的ET模式和LT模式（ET的非阻塞）
    LT模式：
        当epoll_wait检测到fd上有事件发生并将此事件通知应用程序后，应用程序可以不立即处理该事件，这样，当应用程序下一次调用epoll_wait时，epoll_wait还会再次向应用程序通知此事件，直到此事件被处理。
    
    ET模式：
        当epoll_wait检测到fd上有事件发生并将此事件通知应用程序后，应用程序必须立即处理该事件，因为后续的epoll_wait调用将不再向应用程序通知这一事件。
        要求服务端必须一次把数据读完--->循环读数据 (读完数据后，可能会阻塞)  --->将描述符设置成非阻塞模式。
        如果描述符是阻塞的，那么读或写操作将会因没有后续事件而一直处于阻塞状态 (饥渴状态)。

# 查询进程占用CPU的命令（注意要了解到used，buf，cache代表意义）
    PS：查看进程的瞬间状态信息
        列出当前进程的快照
        bsd风格：
        ps -aux  
            a:显示一个终端的所有进程
            u:选择有效的用户id或者是用户名
            X:显示没有控制终端的进程，同时显示各个命令的具体路径。
        显示信息包括：
            USER：    用户名
            PID：    进程ID（Process ID）
            %CPU：    进程的cpu占用率
            %MEM：    进程的内存占用率
            VSZ：    进程所使用的虚存的大小（Virtual Size）
            RSS：    进程使用的驻留集大小或者是实际内存的大小，Kbytes字节。
            TTY：    与进程关联的终端（tty）
            STAT：    进程的状态：进程状态使用字符表示的（STAT的状态码）
            TIME：    进程使用的总cpu时间
            COMMAND：    正在执行的命令行命令

        标准风格：
        ps -ef
            e:显示所有进程
            f:显示全部格式
        显示信息包括：
            UID：    用户ID（User ID）
            PID：    进程ID（Process ID）
            PPID：    父进程的进程ID（Parent Process id）
            STIME：    启动时间
            TTY：    与进程关联的终端（tty）
            TIME：    进程使用的总cpu时间
            CMD：    正在执行的命令行命令

    TOP:查看系统的实时状态信息
        实时显示系统中各个进程的资源占用情况
        top前五行显示统计信息
        第一行：
            当前时间 系统运行时间 当前登录用户数 系统负载（任务队列的平均长度）
        第二行：
            任务总数 运行总数 睡眠总数 停止总数 僵死总数
        第三行：
            用户占用CPU 内核占用CPU 空闲CPU 等待CPU 硬中断CPU 软中断CPU
        第四行：
            物理内存总量 使用的物理内存used 空闲内存free 内核缓存的内存量buff
        第五行：
            交换区总量 使用的交换区used 空闲交换区free 缓冲的交换区cacheed 可用交换区

        计算可用内存数有一个近似的公式： 
        第四行的free + 第四行的buffers + 第五行的cached

        进程信息：默认CPU用量排序
        特定进程信息 top -p pid

# 硬连接和软连接的区别
    Linux下文件存储可以分为元数据和用户数据，其中元数据存储了用户数据的属性信息和索引节点号，用户数据是真实的文件内容，存在磁盘块上。访问一个文件是通过 文件名->索引节点号->磁盘块。

    ln 源文件 目标文件
    A对B进行硬链接，新建一个文件名A，该文件名A指向了B文件的索引节点号，磁盘引用计数+1，删除文件A时，A指向B文件的索引节点号的指针被删除，磁盘块的引用计数-1。

    ln -s 源文件 目标文件
    A对B进行软连接，新建一个文件名A,指向一个新的索引节点号，该索引节点号指向一块新的磁盘块，磁盘块存储的是B文件的路径。可跨系统。

    原理上，硬链接和源文件的inode节点号相同，两者互为硬链接。软连接和源文件的inode节点号不同，进而指向的block也不同，软连接block中存放了源文件的路径名。
    实际上，硬链接和源文件是同一份文件，而软连接是独立的文件，类似于快捷方式，存储着源文件的位置信息便于指向。
    使用限制上，不能对目录创建硬链接，不能对不同文件系统创建硬链接，不能对不存在的文件创建硬链接；可以对目录创建软连接，可以跨文件系统创建软连接，可以对不存在的文件创建软连接。

    每个文件(目录也是文件)都对应着一个inode结构，其中inode数据结构中包含了文件类型(目录，普通文件，符号连接文件等等)的信息，也就是说操作系统在遍历目录时可以判断出符号连接，既然可以判断出符号连接当然就可以采取一些措施来防范进入过大的循环了，系统在连续遇到8个符号连接后就停止遍历，这就是为什么对目录符号连接不会进入死循环的原因了。但是对于硬连接，由于操作系统中采用的数据结构和算法限制，目前是不能防范这种死循环的。

# 文件权限怎么看（rwx）
    ls -al
        a:显示所有目录和文件
        l:以长格式显示目录下的内容列表：件名，文件类型、权限模式、硬连接数、所有者、组、文件大小和文件的最后修改时间

        文件权限包括四个部分
            第一部分：文件类型
            第二部分：所有者权限
            第三部分：所属用户组权限
            第四部分：其他用户权限

            r:可读      4
            w:可写      2
            x：可执行   1 
        
        改变权限：chmod xxx filename
                 chmod 0xxx filename
                 0标识特殊权限位，同样，将第一位转换为二进制也是三部分 a b c,
                    a:setuid,设置使文件在执行阶段具有所有者的权限。
                    b:setgid: 该权限只对目录有效. 目录被设置该位后, 任何用户在此目录下创建的文件都具有和该目录所属的组相同的组。
                    c:sticky bit: 该位可以理解为防删除位. 一个文件是否可以被某用户删除, 主要取决于该文件所属的组是否对该用户具有写权限。
        
        改变文件所属：chown -R username:user_group folder
    
# 文件的三种时间（mtime, atime，ctime），分别在什么时候会改变
    atime:（access time）显示的是文件中的数据最后被访问的时间，比如系统的进程直接使用或通过一些命令和脚本间接使用。（执行一些可执行文件或脚本）
    mtime: （modify time）显示的是文件内容被修改的最后时间，比如用vi编辑时就会被改变。（也就是Block的内容）
    ctime: （change time）显示的是文件的权限、拥有者、所属的组、链接数发生改变时的时间。当然当内容改变时也会随之改变（即inode内容发生改变和Block内容发生改变时）

# Linux监控网络带宽的命令，查看特定进程的占用网络资源情况命令
    netstat查看服务及监听端口
        -t : 指明显示TCP端口
    　　-u : 指明显示UDP端口
    　　-l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序)
    　　-p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序。
    　　-n : 不进行DNS轮询(可以加速操作)
    netstate -nlp:显示进程标识和处于监听状态的tcp端口

    netstate -p pid:查看特定进程的占用网络资源情况

# shell脚本用法
