# 网络的几种分层体系结构
    解除功能耦合，屏蔽不同厂商的差异性，促进发展。

    OSI七层模型
        物理层：指定了硬件设施的规格标准（插口数量尺寸）和电气特性规范（电压的01判断），屏蔽不同物理设施之间的差异性。
        数据链路层：两台物理机器间无中间节点的一条物理路径，数据在该路径上传输数据（封装成帧、透明传输和差错控制）（以太网帧协议）
        网络层：从网络的一个节点将数据传输到网络中的另一个节点（ip协议族） 路由器：路由、存储转发、拥塞控制、呼叫准入
        传输层：完成进程到进程之间的可靠性数据传输（tcp/udp）（端口号）
        会话层：负责建立、管理和终止表示层实体之间的会话连接。
        表示层：内码转换；压缩与解压缩；加密与解密。
        应用层：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。

    tcp/ip四层模型
        数据链路层：两台物理机器间无中间节点的一条物理路径，数据在该路径上传输数据（封装成帧、透明传输和差错控制）（以太网帧协议）
        网络层：从网络的一个节点将数据传输到网络中的另一个节点（ip协议族） 路由器：路由、存储转发、拥塞控制、呼叫准入
        传输层：完成进程到进程之间的可靠性数据传输（tcp/udp）（端口号）
        应用层：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。

    互联网五层模型
        物理层：指定了硬件设施的规格标准（插口数量尺寸）和电气特性规范（电压的01判断），屏蔽不同物理设施之间的差异性。
        数据链路层：两台物理机器间无中间节点的一条物理路径，数据在该路径上传输数据（封装成帧、透明传输和差错控制）（以太网帧协议）
        网络层：从网络的一个节点将数据传输到网络中的另一个节点（ip协议族） 路由器：路由、存储转发、拥塞控制、呼叫准入
        传输层：完成进程到进程之间的可靠性数据传输（tcp/udp）（端口号）
        应用层：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。

# 建立TCP服务器的各个系统调用
    服务器端：建立socket->绑定IP->监听端口->接受连接->while(1){接收消息；回复消息}->关闭连接
    客户端：建立socket->请求连接->while(1){发送消息；接收消息}->关闭连接

    int socket(int family, int type, int protocol);//创建套接字(指定协议族（ipv4、ipv6），指定socket类型(流式、报式、原始)，指定协议（为0协议族默认协议）) 套接字成功返回一个文件描述符。

    int bind(int sockfd, struct sockaddr *my_addr, int addrlen);//将socket与ip及端口相关联（socket描述符，保存ip和端口的结构体（注意大小端字节序转换），结构体字节长度） 绑定成功返回0，失败-1；

    int listen(int sockfd， int backlog); //指定客户端请求队列允许的最大请求数，进入连接请求队列的连接请求将在队列中等待accept(),默认20。（对于每个listen socket 内核会维护两个队列（syn队列，等待三次握手完毕；accept队列，已完成三次握手））
    listen函数在内核维护了两个队列，一个是等待完成握手队列，系统默认大小是128，一个是握手完成队列，由backlog参数设定，一般设为128默认大小（跟系统有关,并发连接），当连接完成，新连接描述符从等待队列添加到完成队列，通过accept函数从该队列获取新连接，如果没有新连接完成，则该进程处于睡眠状态。
    当ESTABLISHED队列达到上限的时候，服务端会启动定时器重新发送SYN-ACK。
    当SYN-RECV队列达到上限的时候，服务器直接丢弃了客户端发送的SYN包。

    int accept(int sockfd, struct sockaddr *addr, int *addrlen);//sockfd是被监听的服务器socket描述符，addr通常是一个指向sockaddr_in变量的指针，该变量用来存放提出连接请求的客户端地址；addrten通常为一个指向值为sizeof(struct sockaddr_in)的整型指针变量。错误发生时返回一个-1并且设置相应的errno值。accept()函数将返回一个新的socket描述符，来供这个新连接来使用，在新的socket描述符上进行数据send()和recv()操作。

    int connect(int sockfd, struct sockaddr *serv_addr, int addrlen); //sockfd是目的服务器的socket描述符；serv_addr是服务器端的IP地址和端口号的地址。遇到错误时返回-1，并且errno中包含相应的错误码。进行客户端程序设计无须调用bind()，因为这种情况下只需知道目的机器的IP地址，而客户通过哪个端口与服务器建立连接并不需要关心，内核会自动选择一个未被占用的端口供客户端来使用。

    int send(int sockfd, const void *msg, int len, int flags); //sockfd是你想用来传输数据的socket描述符，msg是一个指向要发送数据的指针。len是以字节为单位的数据的长度。flags一般情况下置为0（关于该参数的用法可参照man手册）send()函数返回实际上发送出的字节数，可能会少于你希望发送的数据。所以需要对send()的返回值进行测量。当send()返回值与len不匹配时，应该对这种情况进行处理。（注意发送缓冲区和应用缓冲区的数据匹配）

    int recv(int sockfd,void *buf,int len,unsigned int flags); //sockfd是接受数据的socket描述符；buf 是存放接收数据的缓冲区；len是缓冲的长度。flags也被置为0。recv()返回实际上接收的字节数，或当出现错误时，返回-1并置相应的errno值。

    close()和shutdown()——结束数据传输 
    当所有的数据操作结束以后，你可以调用close()函数来释放该socket，从而停止在该socket上的任何数据操作：

    close(sockfd); close()是对套接字的操作，关闭后进程不能在访问这个套接字。
    你也可以调用shutdown()函数来关闭该socket。该函数允许你只停止在某个方向上的数据传输，而一个方向上的数据传输继续进行。如你可以关闭某socket的写操作而允许继续在该socket上接受数据，直至读入所有数据。shutdown是对TCP连接的操作。

    int shutdown(int sockfd,int how); 
    sockfd的含义是显而易见的，而参数 how可以设为下列值： 
　　·0-------不允许继续接收数据 
　　·1-------不允许继续发送数据 
　　·2-------不允许继续发送和接收数据，均为允许则调用close() 
    shutdown在操作成功时返回0，在出现错误时返回-1（并置相应errno）

# socket网络编程中close是一次就能直接关闭的吗，半关闭状态是怎么产生的？
    客户端主动发起关闭请求的状态转换过程：tcp四次挥手
        client发送FIN(FIN_WAIT_1);
        服务端回复ACK(CLOSE_WAIT),客户端(FIN_WAIT_2);
        服务端发送FIN(LAST_ACK)；
        客户端回复ACK(TIME_WAIT),服务端（CLOSED）

    半关闭状态的产生及其原因：
        客户端主动关闭连接，但是服务端没有发送FIN包给客户端，导致服务端长时间停在close_wait状态。导致大量的close_wait的原因可能是多进程开发时，父进程使用socket，子进程进程继承socket，socket计数加1，子进程关闭socket只是引用计数减一，并没有真正地关闭连接，导致大量的close_wait。所以在子进程中关闭连接应该先shutdown，再close。

# TIME_WAIT以及2MSL的作用
    1、安全的终止全双工连接：
        当服务端向客户端发送FIN包，请求关闭连接，客户端回复确认包可能丢失，如果丢失那么服务端就不能正常关闭连接，所以客户端回复确认包后进入TIEM_WAIT状态，如果服务端没有收到确认包，会超时重传FIN包，在TIME_WAIT状态下的客户端会回复FIN请求，服务端收到确认包，正常关闭连接。（等待重传）

    2、避免旧报文对新连接造成影响：
        tcp不允许TIME_WAIT状态建立新的连接，因为当客户端回复服务端确认包可能在网络中滞留，然后客户端又超时重发确认包，服务端正常关闭。如果此时该服务端与客户端新建连接，旧的报文到来将会严重影响新连接的数据传输，因此等待2msl的时间，让旧报文消失在网络中。   

# MTU和MSS
    MTU:链路层规定的最大传输单元，以太网：1500字节
    MSS:TCP规定最大数据段，MSS = MTU - ipheader(20) - tcpheader(20) = 1460
    UDP最大字节 = MTU - 20 - udpheader(8) = 1472
    UDP无重传机制，分片丢包后的后果很严重，要避免分片。

# 对路由协议的了解与介绍
    动态路由会给相邻的路由器发送自己已知的网络连接信息，这些信息会像接力一样依次传递给其他路由器。直到整个网络都了解，生成路由控制表，就可以正确地转发数据包了。随着IP网络的发展，想要对所有的网络统一管理是不可能的，因此人们根据路由控制的范围常使用IGP（内部网关协议）和EGP（外部网关协议）。

    EGP和IGP的关系与IP地址网络部分和主机部分有相似之处，像根据IP地址中的网络部份在网络部份进行路由选择、根据主机部分在链路内部进行主机识别一样，可以根据EGP在区域网络之间进行路由选择，也可根据IGP在区域网络内部进行主机识别。

    内部网关协议：
        距离矢量路由协议：指根据距离（代价）和方向决定目标网络或目标主机位置的一种方法。路由器之间可以互换目标网络方向以及距离相关信息，并以这些信息为基础制作路由控制表，由于只有距离和方向的信息，网络构造复杂时，在获得稳定的路由信息之前需要消耗一定的时间，也极易发生路由循环等问题。
            RIP协议：RIP中无法实现的可变长度子网构造的网络路由控制
                1、将路由控制信息定期广播，将6次还未收到路由信息的路由器相关信息丢弃。
                2、将路由向量写数据库，根据距离选择较短的路径生成路由控制表。距离为路由器跳数，最大跳数为16跳。

        链路状态路由协议：路由器在了解网络整体连接状态的基础上生成路由控制表的一种方法，所有的路由器都持有相同的信息，对于任何同一台路由器网络拓扑都完全一样。因此只要一台路由器与其他路由器保持相同的路由控制信息，就意味该路由器上的信息是正确的。只要每个路由器尽快的与其他路由器同步路由信息就可以使路由信息达到一个稳定的状态，因此即使网络结构复杂，每个路由器也能保持正确的路由信息，进行稳定的路由选择。

            OSPF协议：
                1、宣告OSPF的路由器从所有启动OSPF协议的端口发送hello包，共享一条数据链路的路由器收到hello数据包并且根据hello数据包中的参数进行协商，协商成功则两台路由器形成邻居，互为邻接关系。
                2、每一台路由器在所有形成邻接关系的路由器之间发送链路状态公告（多类型）（LSA:描述路由器所有的链路、接口、邻接关系以及链路状态信息）（划分骨干区域进行转发）
                3、每一台收到LSA的路由器将链路状态信息存储到链路状态数据库中，然后将LSA转发给所有邻居
                4、LSA在网络区域内泛洪，直到所有的路由器形成相同的链路状态数据库信息（利用数据库摘要进行比较异同）
                5、当所有路由器LSDB相同时，每一台路由器以自身为根，使用SPF算法生成一颗无环的最小生成树，作为该路由器的路由控制表
                6、当所有路由器都生成路由控制表后，ospf保持安静，邻居之间只需要保活即可，30s传一次LSA

    外部网关协议：
        BGP:边界网关协议，BGP是唯一一个用来处理像因特网大小的网络的协议，也是唯一能够妥善处理好不相关路由域间的多路连接的协议。BGP构建在EGP的经验之上。BGP 系统的主要功能是和其他的 BGP系统交换网络可达信息。网络可达信息包括列出的自治系统（AS）的信息。这些信息有效地构造了AS互联的拓朴图并由此清除了路由环路，同时在AS级别上可实施策略决策。

# 路由协议所使用的算法
    迪杰斯特拉最短路径算法：
        1、指定起点s
        2、引进集合S(已求出最短路径的顶点及距离)和集合U(未求出最短路径的顶点及距离)（s,v）相邻距离为相邻权值，（s,v）不相邻则距离为无穷
        3、从集合U中找出顶点s最短的路径，更新U集合（(s,k)+(k,v)），一直到U为空。
        4、S集合为顶点s到所有节点的最短路径集合

# 路由表的项目包括哪些
    目的地址，网关地址，目的地址掩码，接口号

# 地址解析协议ARP的过程
    主机A和主机B在同一网段时：
        A先查看主机A的ARP表，确定是否含有主机B对应的ARP表项，如果找到了直接使用主机B对应的MAC地址，封装成帧发送给主机B;如果没找到对应表项，则缓存该数据报文，以广播方式发送ARP请求报文，包括源主机A的ip和MAC,目标主机B的ip和全0的MAC地址，该网段所有主机都可以接受该请求，只有目标主机会单播回复请求（源主机B的ip和mac,目标主机A的ip和mac）,主机A收到主机B的响应，将主机B的mac地址加入主机A的ARP表，同时封装成帧发送给主机B.
    主机A和主机B不在同一网段：主机A先给网关发送ARP请求，目标为网关ip和网关mac，由网关去处理ARp表项回复给主机A。

# 网际控制报文协议ICMP的过程
    分为查询报文和差错报文：
        类型+代码：决定ICMP包的类型（查询不同的网络状态）
        检验和：校验ICMP正确性
        其他选项：依据类型而定
    将差错或者查询信息反馈给主机应用程序，例如：当路由器收到一份ip数据包但是不能转发时，反馈给主机一份“主机不可达”的差错报文。

# ping过程
    ping是测试网络连通性的程序，被称作因特网包探索器。Ping向目标ip发送一个ICMP包，要求目的主机返回一个同样大小的数据包来确定两台主机网络是否连通。
    假设在因特网中ping，主机A ping 主机B。
    ICMP创建回应请求包；IP协议封装ICMP包创建分组；ip协议判断目的ip处于局域网还是远程网络；根据目的ip将数据包转发给默认网关；网关向网络中转发，如果转发过程中，路由表项中找不到目标ip，则像源主机发送目标网络不可达的ICMP报文；如果主机B收到报文，进行检验，ICMP解析这是一个回应请求报文，回应此请求给主机A;主机A收到应答后，继续发送ICMP应答请求包，检测网络质量。
    pathping命令可以提供有关在源和目标之间的中间跃点处网络滞后和网络丢失的信息。

# 动态主机配置协议DHCP的过程
    DHCP客户端广播discover报文，所有的DHCP服务端接收到该报文，并给出响应，发送DHCP offer报文（服务端提供的可用ip包含在内）给客户端，并记录该ip已被分配，客户端只接收第一个包，客户端正式请求该ip时，其他服务端也能收到该ip信息，释放offer中的未使用的ip。

# WAN LAN WLAN VLAN VPN的区别
    LAN是局域网，可以共享的区域网络，可以共享文件和打印机等；
    WAN是广域网，现在的因特网就是这种，一般来说，WAN是直接用名称不可共享的，比如打印机等；
    WLAN是无线局域网，就是常说的WIFI；
    VLAN是虚拟局域网，是网络设备比如交换机等分隔出的一个大局域网中的不同小局域网，可以实现不同的虚拟局域网之间按权限访问，大公司一般都会划分VLAN；
    VPN叫虚拟专用网，是通过用户名密码使用WAN连接两个LAN，让两个不同地域的LAN连接起来像一个LAN中访问一样。

# 介绍一下VPN（虚拟专用网）
    VPN即虚拟专用网，是通过一个公用网络（通常是因特网）建立一个临时的、安全的连接，是一条穿过混乱的公用网络的安全、稳定的隧道。通常，VPN是对企业内部网的扩展，通过它可以帮助远程用户、公司分支机构、商业伙伴及供应商同公司的内部网建立可信的安全连接，并保证数据的安全传输。

# TCP和UDP的区别
    1、tcp面向连接的；udp是无连接的
    2、tcp提供可靠的传输服务，无差错、不丢失、不重复、按序到达；udp尽最大努力交付，不具有可靠性
    3、tcp是流式传输；udp报式传输
    4、tcp有拥塞控制功能，在网络阻塞的时候降低主机发送速率；udp无此功能，对实时应用很有用
    5、tcp首部开销20字节；udp首部开销8字节
    6、tcp的逻辑信道是全双工可靠信道；udp半双工不可靠信道

    场景选择：
        什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输等
        什么时候应该使用UDP：当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP 

# TCP如何保证数据的正确性
    1、数据分段发送
        应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的数据报长度将保持不变。
    2、超时重发
        当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
    3、对于收到的请求，给出确认响应
        当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒 。(之所以推迟，可能是要对包做完整校验)
    4、校验出包有错，丢弃报文段，不给出响应，TCP发送数据端，超时时会重发数据
        TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。
    5、对失序数据进行重新排序，然后才交给应用层
        既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。
    6、对于重复数据，能够丢弃重复数据
        既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据。
    7、TCP可以进行流量控制，防止较快主机致使较慢主机的缓冲区溢出
        TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。TCP使用的流量控制协议是可变大小的滑动窗口协议。
    8、TCP具有拥塞控制功能
        防止过多的数据注入到网络当中，这样可以使网络中的路由器或链路不致过载。

# TCP（UDP，IP）等首部的认识（http请求报文构成）
    UDP：
        1.源端口： 源端口号，需要对方回信时选用，不需要时全部置0
        2.目的端口：目的端口号，在终点交付报文的时候需要用到
        3.长度：UDP的数据报的长度（包括首部和数据）其最小值为8（只有首部）
        4.校验和：检测UDP数据报在传输中是否有错，有错则丢弃

    TCP：
        16位源端口号：16位的源端口中包含初始化通信的端口。源端口和源IP地址的作用是标识报文的返回地址。
        16位目端口号：16位的目的端口域定义传输的目的。这个端口指明报文接收计算机上的应用程序地址接口。
        32位序号: 32位的序列号由接收端计算机使用，重新分段的报文成最初形式。当SYN出现，序列码实际上是初始序列码（Initial Sequence Number，ISN），而第一个数据字节是ISN+1。这个序列号（序列码）可用来补偿传输中的不一致。
        32位确认序号: 32位的序列号由接收端计算机使用，重组分段的报文成最初形式。如果设置了ACK控制位，这个值表示一个准备接收的包的序列码。
        4位首部长度: 表示该tcp报头有多少个4字节(32个bit)
        6位保留: 6位值域，这些位必须是0。为了将来定义新的用途而保留。
        6位标志位：
            URG: 标识紧急指针是否有效
            ACK: 标识确认序号是否有效
            PSH: 用来提示接收端应用程序立刻将数据从tcp缓冲区读走
            RST: 要求重新建立连接. 我们把含有RST标识的报文称为复位报文段
            SYN: 请求建立连接. 我们把含有SYN标识的报文称为同步报文段
            FIN: 通知对端, 本端即将关闭. 我们把含有FIN标识的报文称为结束报文段
        16位窗口大小: 用来表示想收到的每个TCP数据段的大小。TCP的流量控制由连接的每一端通过声明的窗口大小来提供。窗口大小为字节数，起始于确认序号字段指明的值，这个值是接收端正期望接收的字节。窗口大小是一个16字节字段，因而窗口大小最大为65535字节。
        16位检验和: 由发送端填充, 检验形式有CRC校验等. 如果接收端校验不通过, 则认为数据有问题. 此处的校验和不光包含TCP首部, 也包含TCP数据部分.
        16位紧急指针: 指向后面是优先数据的字节，在URG标志设置了时才有效。如果URG标志没有被设置，紧急域作为填充。加快处理标示为紧急的数据段。
        选项：长度不定，但长度必须为1个字节 。如果没有选项就表示这个1字节的域等于0。

# 网络层分片的原因与具体实现
    ip分片是网络传输报文的一种技术手段，当ip报文数据的总长度大于链路数据帧的最大长度（MTU）时,网络层将数据报文拆分为若干分片，每个ip分片的16位识别号唯一记录了一个ip包的ID，片偏移字段记录了该分片位于原包的相对位置，分片将ip数据包发送，接收端将具有同一ID的分片重新组装。当IP数据报被分片后，每一片都成为一个分组，具有自己的IP首部，并在选择路由时与其他分组独立。这样，当数据报的这些片到达目的端时有可能会失序，但是在IP首部中有足够的信息让接收端能正确组装这些数据报片。尽管IP分片过程看起来是透明的，但有一点让人不想使用它：即使只丢失一片数据也要重传整个数据报。因为IP层本身没有超时重传的机制——由更高层来负责超时和重传（TCP有超时和重传机制，但UDP没有。一些UDP应用程序本身也执行超时和重传）。当来自TCP报文段的某一片丢失后，TCP在超时后会重发整个TCP报文段，该报文段对应于一份IP数据报。没有办法只重传数据报中的一个数据报片。事实上，如果对数据报分片的是中间路由器，而不是起始端系统，那么起始端系统就无法知道数据报是如何被分片的。就这个原因，经常需要避免分片。

# TCP的三次握手与四次挥手的详细介绍（TCP连接建立与断开是热门问题）
    三次握手过程：
        第一次握手：客户端发送SYN(seq=x)包给服务端，进入SYN_SEND状态，等待服务器确认。
        第二次握手：服务端收到SYN包，确认客户端的SYN(ACK=x+1),同时发送自己的SYN包（seq=y）给客户端，进入SYN_RECV状态。
        第三次握手：客户端收到服务器SYN+ACK，向服务端发送确认包ACK(ack=y+1)，此时客户端和服务端都进入established状态

    四次挥手过程：
        第一次挥手：主机1发送一个FIN包，主机1进入FIN_WAIT_1状态，表示主机不再发送数据。
        第二次挥手：主机2收到FIN+ACK包，回复主机1一个ACK,主机1进入FIN_WAIT_2状态，表示主机1已经知道主机2知道主机1没有数据要发送了,主机2进入close_wait状态。
        第三次挥手：主机2发送FIN包，请求关闭连接，主机2进入last_ack状态。
        第四次挥手：主机1收到主机2的FIN包，发送ACK,主机1进入TIME_WAIT状态，主机2收到主机1的ACK就关闭连接。此时主机1等待2MSL后没有数据包到来，则证明服务端正常关闭，主机1也关闭连接

# 为什么建立连接是三次握手，而关闭连接却是四次握手
    建立连接时：处于listen状态的服务端收到SYN报文后，服务端将自己的SYN请求包和客户端确认包ACK放在一个报文中发送。
    关闭连接时：服务端收到FIN报文，只是知道客户端不会再向服务端发送数据了，但是服务端数据是否发送完毕不能确认，所以要先响应FIN包，等待自己的数据发送完毕后，再发送FIN包请求关闭连接，所以ACK确认包和FIN请求包一般是分开发送。

# 关闭TCP连接一定需要4次挥手吗
    不一定！4次挥手是TCP关闭连接最安全的做法而已！
    设置socket的SO_LINGER标志来避免socket连接进入TIME_WAIT状态，发送RST强制终止连接，这种做法不安全，但是能够更快的关闭连接，释放更多的资源。

# 为什么使用三次握手，两次握手可不可以
    在进行网络连接时，存在一种异常情况，客户端发起连接请求，但是该连接请求在网络中滞留了，客户端发起新的连接请求，该请求成功建立连接，此时滞留的连接请求已经是无效请求，到达服务端，服务端会认为这是个正常的连接请求，服务端同意建立连接，如果此时不采用三次握手，该次连接也会建立，浪费服务器资源。但是采用三次握手，此时客户端不会理会该请求，不会建立连接。

# TIME_WAIT的意义（为什么要等于2MSL）
    可靠地实现TCP全双工连接的终止：
        在最后一次被动关闭方A发送FIN包后，主动关闭方B的ACK可能丢失，A没有收到ACK确认则超时重传，重发FIN,在2MSL时间内，B收到FIN则重发ACK并更新2MSL，这样使得双方都能够正常进入closeD状态。
    允许旧的报文段在网络中消逝  
        当A发送的ACK在网络中滞留了，A会超时重发一个ACK给B，B收到后正常进入closed状态。正常情况下，滞留的包传到B会被丢弃。但是如果在此时A和B有新的连接建立，该连接中B收到ACK会对当前的数据传输造成破坏。所以，为了避免这种情况，TCP不允许处于TIME_WAIT状态的连接启动新连接。
        2MSL时间过后，滞留的包已经消失，不会再影响新的连接。

# SYN攻击原理
    攻击方伪造发送大量的TCP连接请求，服务端收到连接请求发送SYN请求和ACK,攻击方不回复服务端的SYN请求，使得服务端大量的连接处于半连接状态，资源耗尽而无法处理正常的连接请求
    内核维护的握手等待队列和握手完成队列，握手等待队列满了后，会定时重发syn请求。

# TCP握手以及每一次握手客户端和服务器端处于哪个状态
    11种状态转换过程：
        握手转换
            1、CLOSED：连接关闭或者连接超时的状态,状态转换的假想起点和终点
            2、LISTEN:服务器调用socket、bind、listen函数后，开始监听客户端连接请求，进入listen状态
            3、SYN_SENT:客户端发起连接握手第一阶段，发送SYN包给服务端，进入SYN_SENT状态，等待服务端确认，如果确认超时，客户端进入CLOSED状态
            4、SYN_RCVD:客户端发起连接握手第二阶段，服务器收到客户端的SYN包，进入SYN_RCVD状态，向客户端回复一个SYN+ACK包
            5、ESTABLISHED:客户端发起连接握手第三阶段，客户端收到服务端的ACK+SYN包，进入ESTABLISHD状态，回复一个ACK,服务端收到ACK后也进入ESTTABLISHD状态，可以进行数据传输了

        挥手转换
            6、FIN_WAIT_1:主动请求关闭，第一次挥手，主动方发送FIN数据包，进入FIN_WAIT_1状态，等待被动方回复ACK
            7、CLOSE_WAIT:收到主动方的FIN包后，被动方进入CLOSE_WAIT状态，同时回复ACK
            8、FIN_WAIT_2：主动方收到ACK确认包，进入FIN_WAIT_2状态
            9、LAST_ACK:被动方发送FIN数据包，等待主动方回复ACK,进入LAST_ACK状态
            10、CLOSING：两边同时发起关闭请求时（即主动方发送FIN，等待被动方返回ACK，同时被动方也发送了FIN，主动方接收到了FIN之后，发送ACK给被动方），主动方会由FIN_WAIT_1 进入此状态，等待被动方返回ACK。

            11、TIME_WAIT：
                    由CLOSING进入：同时发起关闭情况下，当主动端接收到ACK后，进入此状态，实际上这里的同时是这样的情况：客户端发起关闭请求，发送FIN之后等待服务器端回应ACK，但此时服务器端同时也发起关闭请求，也发送了FIN，并且被客户端先于ACK接收到。

                    由FIN_WAIT_1进入：发起关闭后，发送了FIN，等待ACK的时候，正好被动方（服务器端）也发起关闭请求，发送了FIN，这时客户端接收到了先前ACK，也收到了对方的FIN，然后发送ACK（对对方FIN的回应），与CLOSING进入的状态不同的是接收到FIN和ACK的先后顺序。

                    由FIN_WAIT_2进入：这是不同时的情况，主动方在完成自身发起的主动关闭请求后，接收到了对方发送过来的FIN，然后回应ACK。

# 超时重传机制
    1、主机A发送数据包给主机B，主机B没有收到数据包，因而没有给主机A发送ACK确认，主机A等待一段时间后重发该数据包
    2、主机A发送数据包给主机B,主机B收到数据包，回复ACk包，该ACK包主机A没有收到，也会认为主机B没有收到数据包，等待一段时间后重发该数据包。这种情况下，主机B可能收到收到重复的数据包，主机B根据序列号丢弃重复的数据包。

    超时时间：动态计算，超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。如果重发一次之后，得不到应答，等待2*500ms后再进行重传。如果任然等不到应答，等待4*500ms进行重传，以指数形式递增。累积到一定的重传次数，TCP认为网络或者对端主机出现异常，强制断开连接。

# TCP滑动窗口协议
    允许发送方在停止并等待确认前发送多个数据分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输，提高网络吞吐量。
    
    建立网络连接的客户端和服务端各自维护自己的发送缓冲区和接收缓冲区。
    在任意时刻，发送方都在发送缓冲区中维护一组连续的允许发送的帧的序列号，称为发送窗口，接收方在接收缓冲区中维护一组允许接收的帧序列号，称为接收窗口。
        停止等待：发送窗口每发送一个数据帧，收到该帧的确认号才继续发送下一个帧
        后退N帧：发送窗口可以在收到上一个数据帧的确认包之前发送多个数据帧，如果中间有数据帧出错，那么发送方将出错帧的后N个数据帧重传
        选择重传：发送窗口可以在收到上一个数据帧的确认包之前发送多个数据帧，如果中间有数据帧出错，接收方告知发送方出错的帧NAK，发送方重传出错的数据帧即可

# tcp定时器
（1）重传计时器
        在滑动窗口协议中，接受窗口会在连续收到的包序列中的最后一个包向接收端发送一个ACK，当网络拥堵的时候，发送端的数据包和接收端的ACK包都有可能丢失。TCP为了保证数据可靠传输，就规定在重传的“时间片”到了以后，如果还没有收到对方的ACK，就重发此包，以避免陷入无限等待中。
    　　当TCP发送报文段时，就创建该特定报文的重传计时器。可能发生两种情况：
        　　1.若在计时器截止时间到之前收到了对此特定报文段的确认，则撤销此计时器。
        　　2.若在收到了对此特定报文段的确认之前计时器截止时间到，则重传此报文段，并将计时器复位。

（2）坚持计时器
        专门对付零窗口通知而设立的，　　
        先来考虑一下情景：发送端向接收端发送数据包知道接受窗口填满了，然后接受窗口告诉发送方接受窗口填满了停止发送数据。此时的状态称为“零窗口”状态，发送端和接收端窗口大小均为0.直到接受TCP发送确认并宣布一个非零的窗口大小。但这个确认会丢失。我们知道TCP中，对确认是不需要发送确认的。若确认丢失了，接受TCP并不知道，而是会认为他已经完成了任务，并等待着发送TCP接着会发送更多的报文段。但发送TCP由于没有收到确认，就等待对方发送确认来通知窗口大小。双方的TCP都在永远的等待着对方。
        要打开这种死锁，TCP为每一个链接使用一个持久计时器。当发送TCP收到窗口大小为0的确认时，就坚持启动计时器。当坚持计时器期限到时，发送TCP就发送一个特殊的报文段，叫做探测报文。这个报文段只有一个字节的数据。他有一个序号，但他的序号永远不需要确认；甚至在计算机对其他部分的数据的确认时该序号也被忽略。探测报文段提醒接受TCP：确认已丢失，必须重传。
        坚持计时器的值设置为重传时间的数值。但是，若没有收到从接收端来的响应，则需发送另一个探测报文段，并将坚持计时器的值加倍和复位。发送端继续发送探测报文段，将坚持计时器设定的值加倍和复位，直到这个值增大到门限值（通常是60秒）为止。在这以后，发送端每个60秒就发送一个探测报文，直到窗口重新打开。

（3）保活计时器
        保活计时器使用在某些实现中，用来防止在两个TCP之间的连接出现长时间的空闲。假定客户打开了到服务器的连接，传送了一些数据，然后就保持静默了。也许这个客户出故障了。在这种情况下，这个连接将永远的处理打开状态。
        要解决这种问题，在大多数的实现中都是使服务器设置保活计时器。每当服务器收到客户的信息，就将计时器复位。通常设置为两小时。若服务器过了两小时还没有收到客户的信息，他就发送探测报文段。若发送了10个探测报文段（每一个像个75秒）还没有响应，就假定客户除了故障，因而就终止了该连接。
        这种连接的断开当然不会使用四次握手，而是直接硬性的中断和客户端的TCP连接。

（4）时间等待计时器
        时间等待计时器是在四次握手的时候使用的。四次握手的简单过程是这样的：假设客户端准备中断连接，首先向服务器端发送一个FIN的请求关闭包（FIN=final），然后由established过渡到FIN-WAIT1状态。服务器收到FIN包以后会发送一个ACK，然后自己有established进入CLOSE-WAIT.此时通信进入半双工状态，即留给服务器一个机会将剩余数据传递给客户端，传递完后服务器发送一个FIN+ACK的包，表示我已经发送完数据可以断开连接了，就这便进入LAST_ACK阶段。客户端收到以后，发送一个ACK表示收到并同意请求，接着由FIN-WAIT2进入TIME-WAIT阶段。服务器收到ACK，结束连接。此时（即客户端发送完ACK包之后），客户端还要等待2MSL（MSL=maxinum segment lifetime最长报文生存时间，2MSL就是两倍的MSL）才能真正的关闭连接。

# 拥塞控制和流量控制的区别
    （发多少？发多快？）
    拥塞控制是防止过多的数据注入到网络中，可以使网络中的路由器或链路不致过载，是一个全局性的过程。 
    流量控制是点对点通信流量的控制，是一个端到端的过程，主要就是抑制发送端发送数据的速率，以便接收端来得及接收。

# TCP拥塞控制，算法名字？（极其重要）
    拥塞判定：
        重传计时器超时

    慢开始：
        原理：
            主机发送数据前需要先探测一下网络的拥塞程度，先把拥塞窗口值设置为一个MSS大小，每收到一个新的报文段确认，就把拥塞窗口值加大一个MSS大小的值，这样逐渐增加拥塞窗口的值。为了避免网络阻塞，需要设置一个慢开始门限值，当拥塞窗口值小于门限时，继续慢开始算法，当拥塞窗口值大于门限值时，转为拥塞避免算法

    拥塞避免（AMID算法：加法增大，乘法减小）：
        原理：
            让拥塞窗口缓慢增大，每经过一个往返时间RTT,就将拥塞窗口值加1，是拥塞窗口值按照线性规律缓慢的增长。

        无论是慢启动算法还是拥塞避免算法，只要判定出现拥塞，就必须将慢开始门限值设置为拥塞窗口的一半，拥塞窗口设置为1，然后使用慢开始算法,这样可以迅速减少网络中的流量

    快重传：
        原理：
            接收方收到一个失序的报文段后立刻发出确认，而不要等待自己发送数据时才进行捎带确认，当发送方收到三个连续的重复确认时，立即重传。

    快恢复：
        原理：
            当发送方连续收到三个重复确认时，执行乘法减小算法：慢开始门限减小为拥塞窗口的一半，开始执行拥塞避免算法，预防网络阻塞。

# 应用层协议常用的端口号
    TCP:    
        FTP：21
        SMTP：25
        HTTP：80
        HTTPS：443
        SSH：22
        DNS:53
    UDP：
        TFTP:69

# http协议与TCP联系
    tcp协议对应传输层，而http协议是基于tcp协议的应用层协议。
    http协议是建立在tcp连接的基础上，当浏览器需要向服务器获取数据的时候，发出一次http请求，该请求通过tcp建立连接通道，当本次请求的数据获取完毕后，http将tcp连接断开，整个过程很短，所以http是一种无状态的短连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过同一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。
    为什么Http是无状态的短连接，而TCP是有状态的长连接？
        Http就是在每次请求完成后就把TCP连接关了，所以是短连接。而我们直接通过Socket编程使用TCP协议的时候，因为我们自己可以通过代码区控制什么时候打开连接什么时候关闭连接，只要我们不通过代码把连接关闭，这个连接就会在客户端和服务端的进程中一直存在，相关状态数据会一直保存着。

# http/1.0 http/1.1 http/2.0 的区别
    http1.0和http1.1的区别
        1、缓存处理：1.0中主要使用header中的if-modified-since，Expires作为缓存选项；在1.1中引入了更多的缓存控制选项，匹配更多的缓存策略。

        2、带宽优化及网络连接的使用：1.0中，若客户端只需要请求服务端某个对象的部分资源，服务端将会把整个对象都发送过来；在1.1中，允许客户端只请求服务端对象的部分资源，服务端返回部分资源。

        3、错误通知管理：1.1中新增了24个错误响应状态码。

        4、host头处理：1.0中每台服务器绑定一个唯一的IP，URL中不包含主机名；1.1中应对一台物理机上多开虚拟机，虚拟机共享IP的场景，请求消息和响应消息支持host头域。

        5、长连接：1.1支持长连接和请求流水线处理，在一个tcp连接上传送多个http请求和响应数据，减少建立和关闭连接的消耗。
    
    http1.x和http2.0的区别
        1、二进制解析：1.x的解析是基于文本的，文本形式多种多样，很难保持健壮性；2.0支持二进制解析，01组合，实现更方便且健壮。

        2、多路复用：每一个连接上可以支持多个请求并行处理，根据请求id，服务端和和客户端可以将请求重新排序组合。（tcp的慢启动会影响http连接起初的传输速度，对于短时性连接十分低效）

        3、header压缩：2.0中要求客户端和服务端各缓存一份header信息，每次通信只是差量更新header。

        4、服务端推送：把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。
        
    http3.0
        有希望成为下一个正式的http版本，QUIC是Google新开发的一个基于UDP的协议，它提供了像TCP一样的传输可靠性保证。
            1、让不同的流之间真正的实现相互独立传输，互不干扰。
            2、内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。

# http的请求方法有哪些？get和post的区别。
    GET和POST的本质上都是一次tcp连接，重大区别在于GET只发送一个数据包，而POST发送两个数据包
        GET:httpHeader和GET包一次性发送给服务端
        POST:先发送httpheader,然后在发送POST数据包
    其他区别：
        GET在浏览器回退时是无害的，而POST会再次提交请求。
        GET产生的URL地址可以被Bookmark，而POST不可以。
        GET请求会被浏览器主动cache，而POST不会，除非手动设置。
        GET请求只能进行url编码，而POST支持多种编码方式。
        GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
        GET请求在URL中传送的参数是有长度限制的，而POST么有。
        对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
        GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
        GET参数通过URL传递，POST放在Request body中。

# http的状态码
    1**	信息，服务器收到请求，需要请求者继续执行操作
    2**	成功，操作被成功接收并处理 200
    3**	重定向，需要进一步的操作以完成请求
    4**	客户端错误，请求包含语法错误或无法完成请求 404 
    5**	服务器错误，服务器在处理请求的过程中发生了错误 500

# http和https的区别，由http升级为https需要做哪些操作
    HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。
    
    安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。
    1、https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。

    2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议。

    3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

    4、http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

    一个域名（你肯定有）
    Web 服务器（Nginx，Apache，IIS都行）
    SSL 证书（最好 CA 机构颁发的）
    进行服务SSL配置

# https的具体实现，怎么确保安全性
    流程演变要点：
        1、保证通信安全的最直接的做法就是客户端和服务端发送数据时对数据进行加密，对称加密效率高且安全，但是对称加密的双方需持有相同的密钥，服务器必须给每一个客户端维护一个不同的密钥，那么必须保证密钥安全的传输给客户端。

        2、非对称加密需要一对密钥：公钥和私钥，公钥加密的数据只有私钥能解密，私钥加密的数据公钥能解密，私钥只有一份保存在服务端，公钥多份分发给客户端，客户端通过公钥加密发送对称密钥给服务端，服务端通过私钥解密，获得客户端的对称密钥，该过程是安全的。但是公钥传给客户端的过程是不安全的。

        3、服务端直接将公钥传送给客户端可能会存在中间人攻击：客户端请求公钥、中间人拦截请求，伪造请求获得服务器公钥，中间人将自己的公钥发送给客户端，那么客户端与服务端的通信数据会被中间人截取并解密。

        4、第三方可信任机构先用私钥对服务器公钥进行加密生成数字证书，再传递给客户端，客户端使用第三方机构公钥对数字证书解密，获得服务器公钥。证书相当于网站的身份证，里面包含网站的各种信息和过期时间，当客户端访问服务器的时候，服务器会首先给客户端传递服务器证书(这个是向CA证书颁发机构申请获取的)，每个浏览器都有一个根证书库，有的浏览器是采用自主的根证书库，而一些浏览器则采取第三方的根证书库，而根证书库是下载客户端浏览器时预先加载根证书的合集(chrome和ie是直接使用系统证书存储库)客户端接收到证书后，使用其本身所信任的CA颁发机构提供的公钥进行解密，如果解密成功则说明没有被掉包

        5、在传输过程中，防止内容被篡改：服务端将证书进行hash，获得一个摘要，摘要用私钥加密后发送给客户端，客户端先解密摘要，解密成功则确认发送方正确，然后对摘要再hash，获得结果与之前的摘要对比，一致则未发生篡改

        6、中间人也可能申请第三方证书，所以本地信任证书要慎重添加

    具体过程：
        首先客户端通过URL访问服务器建立SSL连接。
        服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。
        客户端的服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
        客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
        服务器利用自己的私钥解密出会话密钥。
        建立三次握手
        服务器利用会话密钥加密与客户端之间的通信。

# 在浏览器输入一个URL的流程，这个过程中浏览器做了什么
    浏览器中输入URL->
    浏览器检查缓存（浏览器缓存、系统缓存、文件缓存），有则显示，无则下一步->
    进行DNS解析，获取服务器ip->
    浏览器发起TCP连接请求，经过三次握手，与服务器建立tcp连接->
    发送http请求包，等待服务器响应->
    接收服务器响应的http数据包->
    解析数据包，渲染html页面显示

# URL包括哪三个部分？
    1.协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。
    2.域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用
    3.端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口
    4.虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”
    5.文件名部分：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名
    6.锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分
    7.参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5&ID=24618&page=1”。参数可以允许有多个参数，参数与参数之间用“&”作为分隔符。

# 长连接与短连接的区别以及使用场景
    短连接是指客户端和服务端每次进行数据交互完成都会断开连接，下一次交互数据建立新的连接。长连接是指客户端与服务端建立连接后，连接不断开，通过一个连接可以多次进行数据交互。

    场景：
        长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，每次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

        并发量大，但每个用户无需频繁操作情况下需用短连接好。如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，服务器资源开销大，例如web网站的访问。

# 一个机器能够使用的端口号上限是多少，为什么？可以改变吗？那如果想要用的端口超过这个限制怎么办？
    2^16-1 = 65535,因为0号端口为无效端口，用于分析操作系统
    不可改变
    当tcp使用的端口号大于65535时，底层会将端口号强制转换为范围内的端口：新端口号 = （超过65535的那个端口号 – 65536*倍数 ）

# 介绍一下ping的过程，分别用到了哪些协议
    ping是测试网络连通性的程序，被称作因特网包探索器。Ping向目标ip发送一个ICMP包，要求目的主机返回一个同样大小的数据包来确定两台主机网络是否连通。
    假设在因特网中ping，主机A ping B.
    创建回应请求包；IP协议封装ICMP包创建分组；ip协议判断目的ip处于局域网还是远程网络；根据目的ip将数据包转发给默认网关；网关向网络中转发，如果转发过程中，路由表项中找不到目标ip，则像源主机发送目标网络不可达的ICMP报文；如果主机B收到报文，进行检验，ICMP解析这是一个回应请求报文，回应此请求给主机A;主机A收到应答后，继续发送ICMP应答请求包，检测网络质量。
    pathping命令可以提供有关在源和目标之间的中间跃点处网络滞后和网络丢失的信息。
    IP协议、ICMP协议、ARP协议等

# 对称密码和非对称密码体系
     对称秘钥密码：
        私钥加密，信息的发送和接收方都用同一个秘钥去加密和解密数据，加密解密的速度快，适合大数据量，但秘钥管理困难。
     非对称秘钥密码：
        公钥私钥加密，需要一对秘钥分别完成数据的加密和解密，公开发布的秘钥称为公钥，另一个由用户自己保存的称为私钥。信息的发送方用公钥去加密数据，信息接收方用私钥去解密数据。公钥机制灵活，但加密和解密速度慢。主要作用：身份确认和数据加密
     对称加密算法相比非对称加密算法来说，加解密的效率要高得多。但是缺陷在于对于秘钥的管理上，以及在非安全信道中通讯时，密钥交换的安全性不能保障。所以在实际的网络环境中，会将两者混合使用。

# 数字证书的了解（高频）
    数字证书是指CA机构发行的一种电子文档，是一串能够表明网络用户身份信息的数字，提供了一种在计算机网络上验证网络用户身份的方式，因此数字证书又称为数字标识。数字证书对网络用户在计算机网络交流中的信息和数据等以加密或解密的形式保证了信息和数据的完整性和安全性。（认证所有人和公钥关系；避免中间人攻击）

# 客户端为什么信任第三方证书
    CA中心是一个具权威性、依赖度极高的第三方，其从业资格证书经国家颁发，可有效保障网络数据信息的安全性，使数据信息处国家掌握当中。用户在浏览网络数据信息或进行网上交易时，利用数字证书可保障信息传输及交易的安全性。证明了公钥的正确性，很多软件提供商本地都支持验证CA证书的真实性。

# RSA加密算法（非对称加密，用公匙和私匙实现）
    RSA加密是对明文的E次方后除以N后求余数的过程，密文＝明文E mod N，公钥（E,N）
    RSA解密是对密文的D次方后除以N后求余数的过程，明文＝密文D mod N，私钥（D,N）
    密钥对即为（E,D,N）
    密钥对生成过程：
        求N：
            准备两个质数p,q，p*q=N
        求L(中间过程数)：
            L为p-1和q-1的最小公倍数
        求E:
            1<E<L
            E和L的最大公约数=1
        求D:
            1<D<L
            E*D mod L = 1;

# MD5原理（MD5是密码散列函数）
    MD5算法过程：
        1、处理原文：
            计算原文长度对512取模的结果，若不等于448，则填充原文，第一位填1，其余为填0，使得填充后长度为512*N+448，再用512-448 = 64位，记录长度的二进制，总长度为512*（N+1）
        2、设置初始值：
            MD5的hash长度为128位，32位一组分为4组A,B,C,D,设置4个分组的初始值
        3、循环加工：
            每一次循环都使得旧的ABCD产生新的ABCD,进行原文长度M/512次主循环，每个主循环中有64次子循环。四个非线性函数交替处理ABCD。
        4、拼接结果：
            将最终的ABCD拼接为最终的128位结果

# 数据流和粘包问题
    粘包：
        tcp是流式传输协议，数据采用tcp传输时，多条数据向水流一样通过信道在客户端和服务端传输，每一条数据都是无差别的，数据之间是没有边界区分的，当从读缓冲区读取数据的时候，应用程序无法区分读出的数据是不是一条完整的数据，使得传输的数据粘连在一起，导致应用程序对数据解析错误。
    解决：
        1、定长数据包
        2、数据包尾部加标识符
        3、设计数据结构，包头加包数据长度信息

# 一台机器最多可以建立多少tcp连接
    默认是没有限制的，但是每个连接都会消耗CPU和内存，理论上是机器配置越高，支持的连接更多。
    tcp存在半连接状态，计算机对半连接状态是有限制的；路由器等通讯设备会对连接数有限制。

# 五种IO模型的过程和比较
    对于套接字的输入，第一步是等待数据从网络中到达，当所等待的数据到达时，数据被复制到内核中的缓冲区。第二步则是把数据从内核缓冲区复制到应用进程的缓冲区。 

    根据在这两个不同阶段处理的不同，可以将I/O模型划分为以下五种类型：
        阻塞IO:
            应用进程调用IO函数，然后切换到内核空间中运行，直到数据报到达且被复制到应用进程缓冲区中才返回。我们说进程从调用IO函数开始到它返回的整段时间内是被阻塞的。函数成功返回后，应用进程开始处理数据报。
        非阻塞IO：
            应用进程调用IO函数，然后切换到内核空间运行，内核数据未准备好，立即返回应用程序一个调用错误，循环的调用该IO函数，知道内核数据准备好，拷贝到用户空间，返回成功。进程轮询检查期间，消耗大量CPU。
        IO复用：
            应用进程阻塞，但是IO复用可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。
        信号驱动IO：
            允许套接口进行信号驱动I/O,注册一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，在信号处理函数中调用I/O操作函数处理数据。
        异步IO：
            我们调用aio_read函数，告诉内核，当整个I/O操作完成后通知我们。该系统调用立即返回，而在等待I/O完成期间，应用进程不会被阻塞。当I/O完成（包括数据从内核复制到用户进程）后，内核会产生一个信号通知应用进程，应用进程对数据报进行处理。

# IO多路复用（select，poll，epoll的区别）
    IO多路复用：内核提供的一种同时监控多个文件描述符状态的机制。

    水平触发：是默认/缺省的工作方式，同时支持 block和no_block socket。这种工作方式下，内核会通知你一个fd是否就绪，然后才可以对这个就绪的fd进行I/O操作。就算你没有任何操作，系统还是会继续提示fd已经就绪，不过这种工作方式出错会比较小，传统的select/poll就是这种工作方式的代表。

    边沿触发：是高速工作方式，仅支持no_block socket，这种工作方式下，当fd从未就绪变为就绪时，内核会通知fd已经就绪，并且内核认为你知道该fd已经就绪，不会再次通知了，除非因为某些操作导致fd就绪状态发生变化。如果一直不对这个fd进行I/O操作，导致fd变为未就绪时，内核同样不会发送更多的通知，因为only once。所以这种方式下，出错率比较高，需要增加一些检测程序。边沿模式下每次write或read需要循环write或read直到返回EAGAIN错误。以读操作为例，这是因为ET模式只在socket描述符状态发生变化时才触发事件，如果不一次把socket内核缓冲区的数据读完，会导致socket内核缓冲区中即使还有一部分数据，该socket的可读事件也不会被触发,根据上面的讨论，若ET模式下使用阻塞IO，则程序一定会阻塞在最后一次write或read操作，因此说ET模式下一定要使用非阻塞IO。

    LT可以理解为水平触发，只要有数据可以读，不管怎样都会通知。而ET为边缘触发，只有状态发生变化时才会通知，可以理解为电平变化

    select模型：
        函数原型：int select(int nfds（需要监视的文件描述符最大值+1）, fd_set *readfds（需要检测的可读文件描述符集合）, fd_set *writefds（需要检测的可写文件描述符集合）,fd_set *exceptfds（需要检测的异常文件描述符集合）, struct timeval *timeout（超时时间）);-1失败，0超时，成功>0
        工作流程：初始化fd_set（位图）->将需要监听的套接字加入集合->调用select函数监听描述符，将fd_set拷贝到内核空间，轮询检测数据，将改变的fd_set从内核空间拷贝到用户空间，函数返回->用fd_isset()遍历检测返回的集合中有那些套接字数据准备好->处理数据->
        备注：select模型的检测集合是三个位图，需要轮序检测，默认大小为1024，每次检测返回的所有的数据集合，需要遍历集合去检测具体是哪些文件描述符有数据到来，所以时间复杂度是O(N)的，监听的套接字越多，效率就越低。突破1024的限制，在Windows下可以修改1024的宏，在Linux下需要重新编译内核或者多线程监听，实现线程数*1024。最大特点：跨平台。
    
    poll模型：
        poll模型相对于select模型突破了1024的限制，使用pollfd结构描述集合，将三个描述信息整合到一个结构体中，通过设置事件和事件掩码得到相应事件，采用数组保存多个结构体监听多个文件描述符。
        函数原型：
            int poll (struct pollfd *fds（结构体数组，保存文件描述符）, unsigned int nfds（结构体数组大小+1）, int timeout(超时时间));
            备注：poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

        select/poll的缺点在于：
            1、效率问题：每次进行select调用都会线性扫描全部的fd集合。这样，效率就会呈现线性下降。
            2、内核/用户空间内存拷贝问题：select在解决将fd消息传递给用户空间时采用了内存拷贝的方式。这样，其处理效率不高。
            3、每次在调用开始时，要把当前进程放入各个文件描述符的等待队列。在调用结束后，又把进程从各个等待队列中删除，需要重新维护监控集合。

    epoll模型：
        epoll是为处理大批量句柄而做了改进的poll。
        函数原型：
            int epoll_create(int size);//创建epoll句柄fd，该fd应在epoll使用完成关闭，否则会导致fd耗尽。size参数被忽略。
            int epoll_ctl(int epfd（epoll句柄）, int events(动作类型：添加、修改、删除), int fd（需要监听的fd）, struct epoll_event *event（事件类型）);//epoll的事件注册函数，它不同于select是在监听事件时告诉内核要监听什么类型的事件，而是通过epoll_ctl注册要监听的事件类型。（将新的套接字挂到红黑树上，指明动作类型和事件类型）（增量更新监控描述符）
            int epoll_wait(int epfd(epoll句柄), struct epoll_event *events（内核把发生的事件赋值到该数组））, int maxevents（events数组的大小）, int timeout（超时时间）);
            
            高效性：
                执行epoll_create时，创建了红黑树和就绪list链表；套接字fd会以红黑树的形式保存在内核cache里（slab机制），以支持快速查找、插入和删除。

                执行epoll_ctl时，如果增加fd，则检查在红黑树中是否存在，存在则立即返回，不存在则添加到红黑树中，然后向内核注册回调函数，用于当中断事件到来时向准备就绪的list链表中插入数据。epoll_ctl不需要每次都拷贝所有的fd列表，只需要进行增量式操作。因此，在调用epoll_create函数之后，内核已经在内核开始准备数据结构用于存放需要监控的fd了。其后，每次epoll_ctl只是对这个数据结构进行简单的维护操作即可。

                执行epoll_wait时立即返回准备就绪链表里的数据即可。每次调用epoll_wait，其仅需要从内核态复制少量的fd到用户空间而已。那么，这个准备就绪的list链表是怎么维护的呢？过程如下：当我们执行epoll_ctl时，除了把fd放入到epoll文件系统里file对象对应的红黑树之外，还会给内核中断处理程序注册一个回调函数，其告诉内核，如果这个fd的中断到了，就把它放到准备就绪的list链表中。

# select补充
    1、select有1024的限制在于
        内核实现fd_size的宏声明为1024，Windows直接修改宏，Linux需要重新编译内核。
        系统本身有文件描述符最大的限制，通常跟内存大小有关，一般服务器通常在百万以上。

    2、select内核实现的逻辑（睡眠和唤醒交替）
        select的内核函数入口，调用core_sys_select函数，将用户空间的参数设置监控集合；
        把0~n的fd全部遍历，如果发现可读的fd，立即返回，否则该进程休眠；
        休眠时间到，或者被唤醒，重新遍历fd集合。
    
    3、缺点
        （1）每次调用select，都需要把fd所有集合从用户态拷贝到内核态，这个开销在fd很多时会很大；
        （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大；
        （3）select支持的文件描述符数量太小了，默认是1024；
        （4）select每次返回的是所有的fd集合，从内核态拷贝所有fd到用户态，就绪fd必须遍历通过fd_isset()进行判断。

# poll补充
    1、do_poll 函数第一次查询就OK，直接跳出 for 循环，将进程状态改回running状态，继续执行
    2、do_poll 函数查询失败，进程调度，当前进程进入休眠状态，这个状态下又会产生以下几种情况
        1、在休眠过程中驱动程序条件得到满足，驱动程序唤醒休眠进程，万事大吉
        2、在休眠时间过程中一直不满足，休眠给定时间到达，自动唤醒，再次查询，查询ok 唤醒，查询失败继续休眠给定时间，一直循环下去。

# epoll补充
    LT和ET的区别是在ep_send_events_proc中处理的，如果是LT，不但会将对应的数据返回给用户，并且会将当前的epitem再次加入到rdllist中。这样子，如果下次再次被唤醒就会给用户空间再次返回事件。

    epoll_create
        从slab缓存中创建一个eventpoll对象，并且创建一个匿名的FD跟FD对应的文件对象，
        而eventpoll对象保存在struct file结构的私人指针中，并且返回，
        该fd对应的文件操作只是实现了poll跟释放操作

        创建eventpoll对象的初始化操作
        获取当前用户信息，是不是根，最大监听FD数目等并且保存到eventpoll对象中
        初始化等待队列，初始化就绪链表，初始化红黑树的头结点

    epoll_ctl操作
        将epoll_event结构拷贝到内核空间中
        并且判断加入的FD是否支持轮询结构（epoll的，轮询，selectI / O多路复用必须支持轮询操作）。
        并且从epfd->文件 - > privatedata获取event_poll对象，根据运算区分是添加删除还是修改，
        首先在eventpoll结构中的红黑树查找是否已经存在了相对应的FD，没找到就支持插入操作，否则报重复的错误。
        相对应的修改，删除比较简单就不啰嗦了

        插入操作时，会创建一个与FD对应的epitem结构，并且初始化相关成员，比如保存监听的FD跟文件结构之类的
        重要的是指定了调用poll_wait时的回调函数用于数据就绪时唤醒进程，（其内部，初始化设备的等待队列，将该进程注册到等待队列）完成这一步，我们的epitem就跟这个socket关联起来了，当它有状态变化时，
        会通过ep_poll_callback（）来通知。
        最后调用加入的fd的文件操作 - > poll函数（最后会调用poll_wait操作）用于完成注册操作。
        最后将epitem结构添加到红黑树中

    epoll_wait操作
        计算睡眠时间（如果有），判断eventpoll对象的链表是否为空，不为空那就干活不睡明。并且初始化一个等待队列，把自己挂上去，设置自己的进程状态
        为可睡眠状态。判断是否有信号到来（有的话直接被中断醒来，）如果啥事都没有那就调用schedule_timeout进行睡眠，如果超时或者被唤醒，首先从自己初始化的等待队列删除
        ，然后开始拷贝资源给用户空间了
        拷贝资源则是先把就绪事件链表转移到中间链表，然后挨个遍历拷贝到用户空间，
        并且挨个判断其是否为水平触发，是的话再次插入到就绪链表

    红黑树的作用：（早版本是hashmap）
        增量添加fd时快速进行查找和插入。

# 一个ip配置多个域名，靠什么识别？
    DNS是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP地址数串。
    
# 服务器攻击（DDos攻击）
    DDOS攻击：
        通过多台肉鸡发送大量合法的请求占用大量服务资源,以达到瘫痪网络或者服务器死机的目的。其中SYN Flood洪水攻击利用TCP协议的缺陷,发送大量伪造的TCP连接请求,即在第2次握手前断开连接,使服务器端出于等待响应的状态,从而使得被攻击方资源耗尽(CPU满负荷或内存不足)的攻击方式。
        预防：一是防火墙,也有网关防火墙和路由型防火墙之分。可以抵御大部分的DDOS攻击。再就是CDN加速,把这些攻击分散到镜像服务器上,从而使这些攻击无法对服务器产生过多的影响。最后就是流量清洗,部署专业的设备和方案,对数据流量实时监控,清洗掉异常的流量
    cc攻击：
        攻击者控制肉机不停地发大量数据包给目标服务器,从而造成服务器资源耗尽或网络拥堵。CC可以模拟多个用户不停地进行访问那些需要大量数据操作的页面(数据查询,论坛),造成服务器资源的浪费,由于这些IP都是真实的,数据包也正常,请求都是有效的请求,服务器无法拒绝,从而让CPU长时间处于满载的专题。永远都有处理不完的请求排队,直到正常的访问被中止。预防CC攻击的办法有:把网站尽量做成静态页面、限制连接的数量、修改超时时间、以及分析可疑IP。
    ARP欺骗：
        这类攻击则主要是以窃取用户账户数据资料为目的,通过伪造IP地址和MAC物理地址实现欺骗,也能够在网络中产生大量的ARP通信量使网络阻塞。主要发生在区域网内,攻击者通过发布错误的ARP广播包,阻断正常的网络通信,而且还将自己的电脑伪装成他人的电脑,原本是要发往他人的数据,被发到了入侵者的电脑上,从而达到窃取用户账户数据资料的目的。

# 网络设计模式
    reactor模式：（同步io）
        （1）应用程序注册读就绪事件和相关联的事件处理器
        （2）Reactor阻塞等待内核事件通知
        （3）Reactor收到通知，然后分发可读写事件（读写准备就绪）到用户事件处理函数
        （4）用户读取数据，并处理数据
        （5）事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。

    Proactor模式：（异步io）
        （1）应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。
        （2）事件分离器等待读取操作完成事件
        （3）在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。
        （4）事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。

        Proactor模式中，操作系统相当于直接把IO操作的两阶段工作都给干了，这也要求应用程序在注册异步任务时，需要传递一个缓存区，用来存放结果数据。这里面事件分离器关注的是io的完成事件，而不是就绪时间，当分离器通知应用程序时，应用程序可以直接就能处理数据了。

    Reactor模式就是快递员在楼下，给你打电话告诉你快递到了，你需要自己下楼来拿快递。而在Proactor模式下，快递员直接将快递送到家里面的指定位置。


